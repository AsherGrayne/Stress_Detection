{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Najk15_OKT4Y",
        "outputId": "9ebda643-6f8e-4112-e655-a06ac86a7c5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1926704560.py:86: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  signup_date = (datetime.utcnow() - timedelta(days=signup_days_ago)).date().isoformat()\n",
            "/tmp/ipython-input-1926704560.py:46: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now = datetime.utcnow()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved files:\n",
            " synthetic_users_8000.csv \n",
            " synthetic_tweets_8000_users.csv\n",
            "\n",
            "Users sample:\n",
            " [{'user_id': 1, 'self_harm_flag': 0, 'signup_date': '2018-08-30', 'followers': 150, 'total_tweets_estimate': 962}, {'user_id': 2, 'self_harm_flag': 0, 'signup_date': '2025-07-21', 'followers': 45, 'total_tweets_estimate': 2303}, {'user_id': 3, 'self_harm_flag': 0, 'signup_date': '2023-02-01', 'followers': 8, 'total_tweets_estimate': 1878}, {'user_id': 4, 'self_harm_flag': 0, 'signup_date': '2024-04-08', 'followers': 100, 'total_tweets_estimate': 889}, {'user_id': 5, 'self_harm_flag': 0, 'signup_date': '2018-03-31', 'followers': 61, 'total_tweets_estimate': 4517}]\n",
            "\n",
            "Tweets sample:\n",
            " [{'tweet_id': 1, 'user_id': 1, 'created_at': '2024-08-15T23:31:16.781207Z', 'text': 'Grateful for my friends.', 'is_reply': 0, 'is_retweet': 0, 'like_count': 0, 'retweet_count': 0}, {'tweet_id': 2, 'user_id': 1, 'created_at': '2024-09-01T15:24:02.781293Z', 'text': 'study work', 'is_reply': 0, 'is_retweet': 0, 'like_count': 0, 'retweet_count': 1}, {'tweet_id': 3, 'user_id': 1, 'created_at': '2024-02-23T03:12:44.781328Z', 'text': 'Update: lunch family :-(', 'is_reply': 0, 'is_retweet': 0, 'like_count': 1, 'retweet_count': 0}, {'tweet_id': 4, 'user_id': 1, 'created_at': '2025-10-31T15:15:01.781352Z', 'text': 'Note: Productive day at work.', 'is_reply': 0, 'is_retweet': 0, 'like_count': 1, 'retweet_count': 0}, {'tweet_id': 5, 'user_id': 1, 'created_at': '2025-04-04T07:15:46.781375Z', 'text': 'work travel', 'is_reply': 0, 'is_retweet': 0, 'like_count': 2, 'retweet_count': 0}]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('synthetic_users_8000.csv', 'synthetic_tweets_8000_users.csv', 8000, 678615)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import uuid\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "N_USERS = 8000\n",
        "MIN_TWEETS_PER_USER = 20\n",
        "MAX_TWEETS_PER_USER = 150\n",
        "\n",
        "stress_keywords = [\n",
        "    \"stress\", \"anxiety\", \"depressed\", \"depression\", \"tired\", \"hopeless\", \"alone\", \"worthless\",\n",
        "    \"panic\", \"overwhelmed\", \"can't cope\", \"exhausted\", \"helpless\", \"sad\", \"numb\", \"empty\",\n",
        "    \"hurt\", \"broken\", \"struggle\", \"alone\", \"suicidal thought\", \"give up\"\n",
        "]\n",
        "\n",
        "neutral_words = [\n",
        "    \"work\", \"coffee\", \"movie\", \"football\", \"game\", \"music\", \"lecture\", \"project\", \"lunch\", \"travel\",\n",
        "    \"happy\", \"love\", \"family\", \"friend\", \"weather\", \"tech\", \"code\", \"study\", \"shopping\", \"birthday\"\n",
        "]\n",
        "\n",
        "positive_phrases = [\n",
        "    \"Had a great day!\", \"Feeling good today.\", \"Loved the movie I watched.\", \"Excited for the weekend.\",\n",
        "    \"Grateful for my friends.\", \"Learning new things is fun.\", \"Productive day at work.\"\n",
        "]\n",
        "\n",
        "negative_phrases = [\n",
        "    \"This day has been rough.\", \"Feeling down.\", \"Really tired of everything.\", \"Not my day.\",\n",
        "    \"Things are hard right now.\", \"I can't focus.\", \"Feeling low and drained.\"\n",
        "]\n",
        "\n",
        "templates = [\n",
        "    \"{prefix} {middle} {suffix}\",\n",
        "    \"{middle} {suffix}\",\n",
        "    \"{prefix} {middle}\",\n",
        "    \"{middle}\",\n",
        "    \"{prefix} {suffix}\",\n",
        "    \"{suffix}\"\n",
        "]\n",
        "\n",
        "def rand_date_within(days_back=730):\n",
        "    \"\"\"Return an ISO timestamp within the last `days_back` days\"\"\"\n",
        "    now = datetime.utcnow()\n",
        "    delta = timedelta(days=random.randint(0, days_back), seconds=random.randint(0, 86400))\n",
        "    return (now - delta).isoformat() + \"Z\"\n",
        "\n",
        "def make_tweet_text(is_at_risk):\n",
        "    \"\"\"\n",
        "    Construct a synthetic tweet. Users at risk have higher chance to include stress_keywords and negative phrases.\n",
        "    \"\"\"\n",
        "    parts = []\n",
        "    stress_prob = 0.35 if is_at_risk else 0.06\n",
        "    negative_prob = 0.30 if is_at_risk else 0.08\n",
        "    positive_prob = 0.08 if is_at_risk else 0.25\n",
        "    neutral_prob = 0.30 if not is_at_risk else 0.20\n",
        "\n",
        "    if random.random() < 0.4:\n",
        "        parts.append(random.choice([\"FYI\", \"Update:\", \"Note:\", \"\"]))\n",
        "    mid_roll = random.random()\n",
        "    if mid_roll < stress_prob:\n",
        "        kw = random.choice(stress_keywords)\n",
        "        addon = random.choice(negative_phrases) if random.random() < 0.6 else random.choice(neutral_words)\n",
        "        parts.append(f\"{kw} {addon}\")\n",
        "    elif mid_roll < stress_prob + negative_prob:\n",
        "        parts.append(random.choice(negative_phrases))\n",
        "    elif mid_roll < stress_prob + negative_prob + positive_prob:\n",
        "        parts.append(random.choice(positive_phrases))\n",
        "    else:\n",
        "        parts.append(random.choice(neutral_words) + \" \" + random.choice(neutral_words))\n",
        "    if random.random() < 0.25:\n",
        "        parts.append(random.choice([\"#life\", \"#mood\", \"#work\", \"#tired\", \":-(\", \":)\"]))\n",
        "    if random.random() < 0.05:\n",
        "        parts.append(random.choice([\"Thanks!\", \"Totally\", \"Agreed\", \"Same here\"]))\n",
        "    text = \" \".join([p for p in parts if p]).strip()\n",
        "    if len(text) > 280:\n",
        "        text = text[:277] + \"...\"\n",
        "    return text\n",
        "\n",
        "users = []\n",
        "for uid in range(1, N_USERS+1):\n",
        "    self_harm_flag = np.random.choice([0,1], p=[0.85, 0.15])\n",
        "    signup_days_ago = random.randint(30, 3650)\n",
        "    signup_date = (datetime.utcnow() - timedelta(days=signup_days_ago)).date().isoformat()\n",
        "    followers = max(0, int(np.random.exponential(scale=50)))\n",
        "    total_tweets = random.randint(50, 5000)\n",
        "    users.append({\n",
        "        \"user_id\": uid,\n",
        "        \"self_harm_flag\": int(self_harm_flag),\n",
        "        \"signup_date\": signup_date,\n",
        "        \"followers\": followers,\n",
        "        \"total_tweets_estimate\": total_tweets\n",
        "    })\n",
        "\n",
        "users_df = pd.DataFrame(users)\n",
        "\n",
        "tweets_records = []\n",
        "tweet_id_counter = 1\n",
        "\n",
        "for _, u in users_df.iterrows():\n",
        "    uid = int(u.user_id)\n",
        "    is_at_risk = bool(u.self_harm_flag)\n",
        "    n_tweets = np.random.randint(MIN_TWEETS_PER_USER, MAX_TWEETS_PER_USER+1)\n",
        "    for i in range(n_tweets):\n",
        "        text = make_tweet_text(is_at_risk)\n",
        "        created_at = rand_date_within(days_back=730)\n",
        "        is_reply = random.random() < 0.12\n",
        "        is_retweet = random.random() < 0.08\n",
        "        like_count = int(np.random.poisson(2) + (0 if not is_at_risk else 0))\n",
        "        retweet_count = int(np.random.poisson(0.5))\n",
        "        tweets_records.append({\n",
        "            \"tweet_id\": tweet_id_counter,\n",
        "            \"user_id\": uid,\n",
        "            \"created_at\": created_at,\n",
        "            \"text\": text,\n",
        "            \"is_reply\": int(is_reply),\n",
        "            \"is_retweet\": int(is_retweet),\n",
        "            \"like_count\": like_count,\n",
        "            \"retweet_count\": retweet_count\n",
        "        })\n",
        "        tweet_id_counter += 1\n",
        "\n",
        "tweets_df = pd.DataFrame(tweets_records)\n",
        "\n",
        "users_path = \"synthetic_users_8000.csv\"\n",
        "tweets_path = \"synthetic_tweets_8000_users.csv\"\n",
        "users_df.to_csv(users_path, index=False)\n",
        "tweets_df.to_csv(tweets_path, index=False)\n",
        "\n",
        "try:\n",
        "    from ace_tools import display_dataframe_to_user\n",
        "    display_dataframe_to_user(\"Sample users (8000)\", users_df.sample(5))\n",
        "    display_dataframe_to_user(\"Sample tweets\", tweets_df.sample(8))\n",
        "except Exception:\n",
        "    display = pd.concat([users_df.head(), tweets_df.head()], axis=1)\n",
        "    print(\"Saved files:\\n\", users_path, \"\\n\", tweets_path)\n",
        "    print(\"\\nUsers sample:\\n\", users_df.head().to_dict(orient=\"records\"))\n",
        "    print(\"\\nTweets sample:\\n\", tweets_df.head().to_dict(orient=\"records\"))\n",
        "\n",
        "users_path, tweets_path, len(users_df), len(tweets_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "MFbCdoCjKVWU",
        "outputId": "0d81884b-9dcb-47f0-af9a-0c1b84f3df2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTweets loaded: (678615, 8)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"avg_sentiment\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2309,\n        \"min\": 1,\n        \"max\": 8000,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          2216,\n          2583,\n          1663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1058311474949025,\n        \"min\": -0.23870000000000002,\n        \"max\": 0.41464,\n        \"num_unique_values\": 7991,\n        \"samples\": [\n          0.22683055555555556,\n          0.17660357142857144,\n          0.20271578947368424\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "avg_sentiment"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-11a7dce8-9678-47ba-b707-70ce8d567f60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>avg_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.206052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.111158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.314644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.169123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.168094</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11a7dce8-9678-47ba-b707-70ce8d567f60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11a7dce8-9678-47ba-b707-70ce8d567f60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11a7dce8-9678-47ba-b707-70ce8d567f60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4c88465a-d03b-46f0-89ef-a2d95414f2d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c88465a-d03b-46f0-89ef-a2d95414f2d5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4c88465a-d03b-46f0-89ef-a2d95414f2d5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   user_id  avg_sentiment\n",
              "0        1       0.206052\n",
              "1        2       0.111158\n",
              "2        3       0.314644\n",
              "3        4       0.169123\n",
              "4        5       0.168094"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install vaderSentiment --quiet\n",
        "\n",
        "import pandas as pd\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "tweets = pd.read_csv(\"synthetic_tweets_8000_users.csv\")\n",
        "print(\"Tweets loaded:\", tweets.shape)\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_sentiment(text):\n",
        "    try:\n",
        "        return analyzer.polarity_scores(text)[\"compound\"]\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "tweets[\"sentiment_score\"] = tweets[\"text\"].apply(get_sentiment)\n",
        "\n",
        "avg_sentiment = (\n",
        "    tweets.groupby(\"user_id\")[\"sentiment_score\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "avg_sentiment.columns = [\"user_id\", \"avg_sentiment\"]\n",
        "\n",
        "avg_sentiment.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ani6XAcqLdMm",
        "outputId": "6b7b0d14-94d4-4416-b441-a89a4c57718d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"neg_tweet_ratio\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2309,\n        \"min\": 1,\n        \"max\": 8000,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          2216,\n          2583,\n          1663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neg_tweet_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11944239384614232,\n        \"min\": 0.0,\n        \"max\": 0.6428571428571429,\n        \"num_unique_values\": 1689,\n        \"samples\": [\n          0.20270270270270271,\n          0.5083333333333333,\n          0.05405405405405406\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "neg_tweet_ratio"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-976c444d-6bf6-44c1-aa43-ba903a4e5404\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>neg_tweet_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.162791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.012821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.101266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.141732</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-976c444d-6bf6-44c1-aa43-ba903a4e5404')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-976c444d-6bf6-44c1-aa43-ba903a4e5404 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-976c444d-6bf6-44c1-aa43-ba903a4e5404');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f6ef3a48-70e3-4ede-943a-f8ce9ea1d0fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f6ef3a48-70e3-4ede-943a-f8ce9ea1d0fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f6ef3a48-70e3-4ede-943a-f8ce9ea1d0fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   user_id  neg_tweet_ratio\n",
              "0        1         0.162791\n",
              "1        2         0.160000\n",
              "2        3         0.012821\n",
              "3        4         0.101266\n",
              "4        5         0.141732"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv(\"synthetic_tweets_8000_users.csv\")\n",
        "\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "if \"sentiment_score\" not in tweets.columns:\n",
        "    tweets[\"sentiment_score\"] = tweets[\"text\"].apply(\n",
        "        lambda x: analyzer.polarity_scores(x)[\"compound\"]\n",
        "    )\n",
        "\n",
        "tweets[\"is_negative\"] = tweets[\"sentiment_score\"] <= -0.05\n",
        "\n",
        "neg_tweet_ratio = (\n",
        "    tweets.groupby(\"user_id\")[\"is_negative\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "neg_tweet_ratio.columns = [\"user_id\", \"neg_tweet_ratio\"]\n",
        "\n",
        "neg_tweet_ratio.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjCq40VL4im",
        "outputId": "cc8d4c84-0c95-4c24-e319-5c2071f3398e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   user_id  stress_keywords_freq_total\n",
              " 0        1                          11\n",
              " 1        2                           6\n",
              " 2        3                           1\n",
              " 3        4                           6\n",
              " 4        5                          12,\n",
              "    user_id  stress_keywords_freq_tweets\n",
              " 0        1                           10\n",
              " 1        2                            6\n",
              " 2        3                            1\n",
              " 3        4                            6\n",
              " 4        5                           12)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets = pd.read_csv(\"synthetic_tweets_8000_users.csv\")\n",
        "\n",
        "stress_keywords = [\n",
        "    \"stress\", \"tired\", \"depressed\", \"anxiety\", \"worthless\",\n",
        "    \"panic\", \"alone\", \"sad\", \"hopeless\", \"fail\", \"overwhelmed\",\n",
        "    \"empty\", \"hurt\", \"struggle\", \"helpless\", \"broken\"\n",
        "]\n",
        "\n",
        "stress_keywords = [w.lower() for w in stress_keywords]\n",
        "\n",
        "def count_stress_words(text):\n",
        "    text = str(text).lower()\n",
        "    return sum(1 for w in stress_keywords if w in text)\n",
        "\n",
        "tweets[\"stress_word_count\"] = tweets[\"text\"].apply(count_stress_words)\n",
        "\n",
        "stress_keywords_total = (\n",
        "    tweets.groupby(\"user_id\")[\"stress_word_count\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "stress_keywords_total.columns = [\"user_id\", \"stress_keywords_freq_total\"]\n",
        "\n",
        "tweets[\"has_stress_word\"] = tweets[\"stress_word_count\"] > 0\n",
        "\n",
        "stress_keywords_tweet_count = (\n",
        "    tweets.groupby(\"user_id\")[\"has_stress_word\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "stress_keywords_tweet_count.columns = [\"user_id\", \"stress_keywords_freq_tweets\"]\n",
        "\n",
        "stress_keywords_total.head(), stress_keywords_tweet_count.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "indRH-PyMIhd",
        "outputId": "3e563c3e-cbc3-49a0-ddb2-25a096628deb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"past_month_activity\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2309,\n        \"min\": 1,\n        \"max\": 8000,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          2216,\n          2583,\n          1663\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_month_activity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 16,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          1,\n          3,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "past_month_activity"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7da210d3-3154-47a2-b52a-e9ad25b85c0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>past_month_activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7da210d3-3154-47a2-b52a-e9ad25b85c0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7da210d3-3154-47a2-b52a-e9ad25b85c0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7da210d3-3154-47a2-b52a-e9ad25b85c0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89b99a69-dbb4-4785-a3c8-7a14e83639c0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89b99a69-dbb4-4785-a3c8-7a14e83639c0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89b99a69-dbb4-4785-a3c8-7a14e83639c0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   user_id  past_month_activity\n",
              "0        1                    1\n",
              "1        2                    3\n",
              "2        3                    3\n",
              "3        4                    1\n",
              "4        5                   10"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "\n",
        "tweets = pd.read_csv(\"synthetic_tweets_8000_users.csv\")\n",
        "\n",
        "tweets[\"created_at\"] = pd.to_datetime(tweets[\"created_at\"], errors=\"coerce\")\n",
        "\n",
        "latest_time = tweets[\"created_at\"].max()\n",
        "\n",
        "cutoff_date = latest_time - timedelta(days=30)\n",
        "\n",
        "tweets[\"is_recent\"] = tweets[\"created_at\"] >= cutoff_date\n",
        "\n",
        "past_month_activity = (\n",
        "    tweets.groupby(\"user_id\")[\"is_recent\"]\n",
        "    .sum()\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "past_month_activity.columns = [\"user_id\", \"past_month_activity\"]\n",
        "\n",
        "past_month_activity.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "AOo2zi3XMXD6",
        "outputId": "8b7477a6-4f08-4d9f-f39f-770d1514fd18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded shapes -> users: (8000, 5)  tweets: (678615, 8)\n",
            "Filled missing values (total missing cells before fill): 0\n",
            "Saved final ML dataset to: /content/final_ml_dataset_8000.csv\n",
            "\n",
            "Final dataset shape: (8000, 11)\n",
            "\n",
            "Columns: ['user_id', 'self_harm_flag', 'signup_date', 'followers', 'total_tweets_estimate', 'avg_sentiment', 'neg_tweet_ratio', 'stress_keywords_freq_total', 'stress_keywords_freq_tweets', 'past_month_activity', 'tweet_activity_ratio']\n",
            "\n",
            "Target balance (self_harm_flag):\n",
            "self_harm_flag\n",
            "0    6797\n",
            "1    1203\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample rows:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"# ---------- End of cell ----------\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"self_harm_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"signup_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-07-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"followers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 8,\n        \"max\": 150,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_tweets_estimate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1474,\n        \"min\": 889,\n        \"max\": 4517,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07558566432490113,\n        \"min\": 0.111158,\n        \"max\": 0.31464358974358975,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.111158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neg_tweet_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06255045074579142,\n        \"min\": 0.01282051282051282,\n        \"max\": 0.16279069767441862,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stress_keywords_freq_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2,\n        \"max\": 13,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stress_keywords_freq_tweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2,\n        \"max\": 12,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_month_activity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_activity_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0004746045342383023,\n        \"min\": 0.0010395010395010396,\n        \"max\": 0.002213858755811379,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0013026487190620929\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-0b44c446-2a36-46ea-954c-79910996a81e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>self_harm_flag</th>\n",
              "      <th>signup_date</th>\n",
              "      <th>followers</th>\n",
              "      <th>total_tweets_estimate</th>\n",
              "      <th>avg_sentiment</th>\n",
              "      <th>neg_tweet_ratio</th>\n",
              "      <th>stress_keywords_freq_total</th>\n",
              "      <th>stress_keywords_freq_tweets</th>\n",
              "      <th>past_month_activity</th>\n",
              "      <th>tweet_activity_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-08-30</td>\n",
              "      <td>150</td>\n",
              "      <td>962</td>\n",
              "      <td>0.206052</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>13</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-07-21</td>\n",
              "      <td>45</td>\n",
              "      <td>2303</td>\n",
              "      <td>0.111158</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-02-01</td>\n",
              "      <td>8</td>\n",
              "      <td>1878</td>\n",
              "      <td>0.314644</td>\n",
              "      <td>0.012821</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.001597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-04-08</td>\n",
              "      <td>100</td>\n",
              "      <td>889</td>\n",
              "      <td>0.169123</td>\n",
              "      <td>0.101266</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0.001125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-03-31</td>\n",
              "      <td>61</td>\n",
              "      <td>4517</td>\n",
              "      <td>0.168094</td>\n",
              "      <td>0.141732</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>0.002214</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b44c446-2a36-46ea-954c-79910996a81e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b44c446-2a36-46ea-954c-79910996a81e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b44c446-2a36-46ea-954c-79910996a81e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-52699fd8-503e-44a8-b4c6-a07897f97ff5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52699fd8-503e-44a8-b4c6-a07897f97ff5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-52699fd8-503e-44a8-b4c6-a07897f97ff5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   user_id  self_harm_flag signup_date  followers  total_tweets_estimate  \\\n",
              "0        1               0  2018-08-30        150                    962   \n",
              "1        2               0  2025-07-21         45                   2303   \n",
              "2        3               0  2023-02-01          8                   1878   \n",
              "3        4               0  2024-04-08        100                    889   \n",
              "4        5               0  2018-03-31         61                   4517   \n",
              "\n",
              "   avg_sentiment  neg_tweet_ratio  stress_keywords_freq_total  \\\n",
              "0       0.206052         0.162791                          13   \n",
              "1       0.111158         0.160000                           6   \n",
              "2       0.314644         0.012821                           2   \n",
              "3       0.169123         0.101266                           6   \n",
              "4       0.168094         0.141732                          12   \n",
              "\n",
              "   stress_keywords_freq_tweets  past_month_activity  tweet_activity_ratio  \n",
              "0                           11                    1              0.001040  \n",
              "1                            6                    3              0.001303  \n",
              "2                            2                    3              0.001597  \n",
              "3                            6                    1              0.001125  \n",
              "4                           12                   10              0.002214  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timedelta\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "users = pd.read_csv(\"synthetic_users_8000.csv\")\n",
        "tweets = pd.read_csv(\"synthetic_tweets_8000_users.csv\")\n",
        "\n",
        "print(\"Loaded shapes -> users:\", users.shape, \" tweets:\", tweets.shape)\n",
        "\n",
        "tweets[\"created_at\"] = pd.to_datetime(tweets[\"created_at\"], errors=\"coerce\")\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def safe_sentiment(text):\n",
        "    try:\n",
        "        return analyzer.polarity_scores(str(text))[\"compound\"]\n",
        "    except Exception:\n",
        "        return 0.0\n",
        "\n",
        "if \"sentiment_score\" not in tweets.columns:\n",
        "    tweets[\"sentiment_score\"] = tweets[\"text\"].apply(safe_sentiment)\n",
        "\n",
        "avg_sentiment = tweets.groupby(\"user_id\")[\"sentiment_score\"].mean().reset_index()\n",
        "avg_sentiment.columns = [\"user_id\", \"avg_sentiment\"]\n",
        "\n",
        "tweets[\"is_negative\"] = tweets[\"sentiment_score\"] <= -0.05\n",
        "neg_tweet_ratio = tweets.groupby(\"user_id\")[\"is_negative\"].mean().reset_index()\n",
        "neg_tweet_ratio.columns = [\"user_id\", \"neg_tweet_ratio\"]\n",
        "\n",
        "stress_keywords = [\n",
        "    \"stress\", \"tired\", \"depressed\", \"depression\", \"anxiety\", \"worthless\",\n",
        "    \"panic\", \"alone\", \"sad\", \"hopeless\", \"fail\", \"overwhelmed\",\n",
        "    \"empty\", \"hurt\", \"struggle\", \"helpless\", \"broken\", \"give up\"\n",
        "]\n",
        "stress_keywords = [w.lower() for w in stress_keywords]\n",
        "\n",
        "def count_stress_words(text):\n",
        "    t = str(text).lower()\n",
        "    return sum(t.count(w) for w in stress_keywords)\n",
        "\n",
        "tweets[\"stress_word_count\"] = tweets[\"text\"].apply(count_stress_words)\n",
        "tweets[\"has_stress_word\"] = tweets[\"stress_word_count\"] > 0\n",
        "\n",
        "stress_keywords_total = tweets.groupby(\"user_id\")[\"stress_word_count\"].sum().reset_index()\n",
        "stress_keywords_total.columns = [\"user_id\", \"stress_keywords_freq_total\"]\n",
        "\n",
        "stress_keywords_tweetcount = tweets.groupby(\"user_id\")[\"has_stress_word\"].sum().reset_index()\n",
        "stress_keywords_tweetcount.columns = [\"user_id\", \"stress_keywords_freq_tweets\"]\n",
        "\n",
        "latest_time = tweets[\"created_at\"].max()\n",
        "cutoff_date = latest_time - timedelta(days=30)\n",
        "tweets[\"is_recent\"] = tweets[\"created_at\"] >= cutoff_date\n",
        "\n",
        "past_month_activity = tweets.groupby(\"user_id\")[\"is_recent\"].sum().reset_index()\n",
        "past_month_activity.columns = [\"user_id\", \"past_month_activity\"]\n",
        "\n",
        "frames = [\n",
        "    users,\n",
        "    avg_sentiment,\n",
        "    neg_tweet_ratio,\n",
        "    stress_keywords_total,\n",
        "    stress_keywords_tweetcount,\n",
        "    past_month_activity\n",
        "]\n",
        "\n",
        "from functools import reduce\n",
        "final_df = reduce(lambda left, right: pd.merge(left, right, on=\"user_id\", how=\"left\"), frames)\n",
        "\n",
        "num_missing = final_df.isnull().sum().sum()\n",
        "final_df[\"avg_sentiment\"] = final_df[\"avg_sentiment\"].fillna(0.0)\n",
        "final_df[\"neg_tweet_ratio\"] = final_df[\"neg_tweet_ratio\"].fillna(0.0)\n",
        "final_df[\"stress_keywords_freq_total\"] = final_df[\"stress_keywords_freq_total\"].fillna(0).astype(int)\n",
        "final_df[\"stress_keywords_freq_tweets\"] = final_df[\"stress_keywords_freq_tweets\"].fillna(0).astype(int)\n",
        "final_df[\"past_month_activity\"] = final_df[\"past_month_activity\"].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Filled missing values (total missing cells before fill): {num_missing}\")\n",
        "\n",
        "final_df[\"tweet_activity_ratio\"] = final_df[\"past_month_activity\"] / (final_df[\"total_tweets_estimate\"].replace(0, np.nan))\n",
        "final_df[\"tweet_activity_ratio\"] = final_df[\"tweet_activity_ratio\"].fillna(0.0)\n",
        "\n",
        "out_path = \"/content/final_ml_dataset_8000.csv\"\n",
        "final_df.to_csv(out_path, index=False)\n",
        "print(\"Saved final ML dataset to:\", out_path)\n",
        "\n",
        "print(\"\\nFinal dataset shape:\", final_df.shape)\n",
        "print(\"\\nColumns:\", final_df.columns.tolist())\n",
        "print(\"\\nTarget balance (self_harm_flag):\")\n",
        "print(final_df[\"self_harm_flag\"].value_counts(dropna=False))\n",
        "\n",
        "print(\"\\nSample rows:\")\n",
        "final_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCe3r2vtMqiX",
        "outputId": "355ba770-84d8-4456-9795-0720e0ad4ac4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (8000, 11)\n",
            "\n",
            "================ LOGISTIC REGRESSION ================\n",
            "Accuracy: 0.9965\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1699\n",
            "           1       0.99      0.99      0.99       301\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1696    3]\n",
            " [   4  297]]\n",
            "\n",
            "====================== SVM (RBF) =====================\n",
            "Accuracy: 0.9965\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1699\n",
            "           1       0.99      0.99      0.99       301\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1696    3]\n",
            " [   4  297]]\n",
            "\n",
            "==================== RANDOM FOREST ===================\n",
            "Accuracy: 0.9955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1699\n",
            "           1       0.99      0.98      0.99       301\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1695    4]\n",
            " [   5  296]]\n",
            "\n",
            "======================== XGBOOST =====================\n",
            "Accuracy: 0.996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1699\n",
            "           1       0.99      0.99      0.99       301\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       0.99      0.99      0.99      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[1695    4]\n",
            " [   4  297]]\n",
            "\n",
            "\n",
            "================== ACCURACY COMPARISON ==================\n",
            "Logistic Regression: 0.9965\n",
            "SVM (RBF):           0.9965\n",
            "Random Forest:       0.9955\n",
            "XGBoost:             0.9960\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "df = pd.read_csv(\"final_ml_dataset_8000.csv\")\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "df.head()\n",
        "\n",
        "feature_cols = [\n",
        "    \"avg_sentiment\",\n",
        "    \"neg_tweet_ratio\",\n",
        "    \"stress_keywords_freq_total\",\n",
        "    \"stress_keywords_freq_tweets\",\n",
        "    \"past_month_activity\",\n",
        "    \"followers\",\n",
        "    \"tweet_activity_ratio\"\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"self_harm_flag\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr = LogisticRegression(max_iter=3000)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "lr_pred = lr.predict(X_test_scaled)\n",
        "lr_acc = accuracy_score(y_test, lr_pred)\n",
        "\n",
        "print(\"\\n================ LOGISTIC REGRESSION ================\")\n",
        "print(\"Accuracy:\", lr_acc)\n",
        "print(classification_report(y_test, lr_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, lr_pred))\n",
        "\n",
        "\n",
        "svm = SVC(kernel=\"rbf\", probability=True)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "svm_pred = svm.predict(X_test_scaled)\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "\n",
        "print(\"\\n====================== SVM (RBF) =====================\")\n",
        "print(\"Accuracy:\", svm_acc)\n",
        "print(classification_report(y_test, svm_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, svm_pred))\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    class_weight=\"balanced\"\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_acc = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "print(\"\\n==================== RANDOM FOREST ===================\")\n",
        "print(\"Accuracy:\", rf_acc)\n",
        "print(classification_report(y_test, rf_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, rf_pred))\n",
        "\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=250,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.07,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    eval_metric=\"logloss\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
        "\n",
        "print(\"\\n======================== XGBOOST =====================\")\n",
        "print(\"Accuracy:\", xgb_acc)\n",
        "print(classification_report(y_test, xgb_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, xgb_pred))\n",
        "\n",
        "\n",
        "print(\"\\n\\n================== ACCURACY COMPARISON ==================\")\n",
        "print(f\"Logistic Regression: {lr_acc:.4f}\")\n",
        "print(f\"SVM (RBF):           {svm_acc:.4f}\")\n",
        "print(f\"Random Forest:       {rf_acc:.4f}\")\n",
        "print(f\"XGBoost:             {xgb_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6dsdWLBNKpV",
        "outputId": "bcd569ec-4afc-41a9-ba3c-8cc88346666f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.19.0\n",
            "GPUs: []\n",
            "Mixed precision enabled!\n",
            "Strategy replicas: 1\n",
            "Loading: /content/final_ml_dataset_8000.csv\n",
            "Loaded shape: (8000, 11)\n",
            "Added feature crosses: [('total_tweets_estimate', 'followers'), ('total_tweets_estimate', 'stress_keywords_freq_total'), ('total_tweets_estimate', 'stress_keywords_freq_tweets'), ('total_tweets_estimate', 'signup_date_day'), ('total_tweets_estimate', 'signup_date_month'), ('total_tweets_estimate', 'signup_date_year'), ('total_tweets_estimate', 'past_month_activity'), ('total_tweets_estimate', 'signup_date_dow'), ('total_tweets_estimate', 'neg_tweet_ratio'), ('total_tweets_estimate', 'avg_sentiment'), ('total_tweets_estimate', 'tweet_activity_ratio'), ('total_tweets_estimate', 'signup_date_hour'), ('followers', 'stress_keywords_freq_total'), ('followers', 'stress_keywords_freq_tweets'), ('followers', 'signup_date_day'), ('followers', 'signup_date_month'), ('followers', 'signup_date_year'), ('followers', 'past_month_activity'), ('followers', 'signup_date_dow'), ('followers', 'neg_tweet_ratio')]\n",
            "Input dim: 33 Num classes: 2\n",
            "\n",
            "================================================================================\n",
            "Training for 15 epochs...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99219, saving model to /content/job/model_15.keras\n",
            "10/10 - 5s - 511ms/step - accuracy: 0.8955 - loss: 0.2832 - val_accuracy: 0.9922 - val_loss: 0.1131 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002995376925399572.\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.99219 to 0.99687, saving model to /content/job/model_15.keras\n",
            "10/10 - 1s - 145ms/step - accuracy: 0.9973 - loss: 0.0790 - val_accuracy: 0.9969 - val_loss: 0.0663 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0029815362043905283.\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.99687 to 0.99844, saving model to /content/job/model_15.keras\n",
            "10/10 - 1s - 146ms/step - accuracy: 0.9990 - loss: 0.0660 - val_accuracy: 0.9984 - val_loss: 0.0638 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0029585631696203954.\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9986 - loss: 0.0631 - val_accuracy: 0.9984 - val_loss: 0.0620 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.002926599457487842.\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9992 - loss: 0.0606 - val_accuracy: 0.9984 - val_loss: 0.0606 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0028858421349071766.\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 128ms/step - accuracy: 0.9990 - loss: 0.0601 - val_accuracy: 0.9984 - val_loss: 0.0606 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002836542484325295.\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.99844\n",
            "10/10 - 2s - 151ms/step - accuracy: 0.9996 - loss: 0.0594 - val_accuracy: 0.9984 - val_loss: 0.0603 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0027790044544818322.\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.99844\n",
            "10/10 - 3s - 254ms/step - accuracy: 0.9996 - loss: 0.0592 - val_accuracy: 0.9984 - val_loss: 0.0610 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0027135827864641087.\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9990 - loss: 0.0590 - val_accuracy: 0.9984 - val_loss: 0.0600 - learning_rate: 0.0027\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002640680826610367.\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 134ms/step - accuracy: 0.9996 - loss: 0.0589 - val_accuracy: 0.9984 - val_loss: 0.0600 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002560748039745465.\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9994 - loss: 0.0586 - val_accuracy: 0.9977 - val_loss: 0.0591 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.002474277238080777.\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9996 - loss: 0.0583 - val_accuracy: 0.9984 - val_loss: 0.0600 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0023818015428630217.\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 128ms/step - accuracy: 0.9994 - loss: 0.0582 - val_accuracy: 0.9984 - val_loss: 0.0590 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022838910975045085.\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 138ms/step - accuracy: 0.9994 - loss: 0.0581 - val_accuracy: 0.9984 - val_loss: 0.0597 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0021811495524593984.\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 148ms/step - accuracy: 0.9998 - loss: 0.0576 - val_accuracy: 0.9984 - val_loss: 0.0608 - learning_rate: 0.0022\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "Test accuracy after 15 epochs → 0.994375\n",
            "\n",
            "================================================================================\n",
            "Training for 150 epochs...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99687, saving model to /content/job/model_150.keras\n",
            "10/10 - 4s - 373ms/step - accuracy: 0.8941 - loss: 0.3136 - val_accuracy: 0.9969 - val_loss: 0.1170 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002995376925399572.\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.99687\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9961 - loss: 0.0885 - val_accuracy: 0.9961 - val_loss: 0.0682 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0029815362043905283.\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.99687\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9979 - loss: 0.0680 - val_accuracy: 0.9969 - val_loss: 0.0646 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0029585631696203954.\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.99687 to 0.99766, saving model to /content/job/model_150.keras\n",
            "10/10 - 1s - 149ms/step - accuracy: 0.9986 - loss: 0.0644 - val_accuracy: 0.9977 - val_loss: 0.0619 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.002926599457487842.\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.99766 to 0.99922, saving model to /content/job/model_150.keras\n",
            "10/10 - 2s - 177ms/step - accuracy: 0.9986 - loss: 0.0624 - val_accuracy: 0.9992 - val_loss: 0.0596 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0028858421349071766.\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 196ms/step - accuracy: 0.9990 - loss: 0.0608 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002836542484325295.\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 169ms/step - accuracy: 0.9996 - loss: 0.0597 - val_accuracy: 0.9992 - val_loss: 0.0589 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0027790044544818322.\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9990 - loss: 0.0599 - val_accuracy: 0.9992 - val_loss: 0.0584 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0027135827864641087.\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9994 - loss: 0.0590 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 0.0027\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002640680826610367.\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9996 - loss: 0.0587 - val_accuracy: 0.9992 - val_loss: 0.0578 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002560748039745465.\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9994 - loss: 0.0587 - val_accuracy: 0.9992 - val_loss: 0.0584 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.002474277238080777.\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9994 - loss: 0.0586 - val_accuracy: 0.9992 - val_loss: 0.0579 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0023818015428630217.\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 0.9998 - loss: 0.0580 - val_accuracy: 0.9992 - val_loss: 0.0588 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022838910975045085.\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 0.9996 - loss: 0.0578 - val_accuracy: 0.9992 - val_loss: 0.0588 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0021811495524593984.\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 211ms/step - accuracy: 0.9998 - loss: 0.0574 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 0.0022\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0020742103435179254.\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 178ms/step - accuracy: 0.9998 - loss: 0.0573 - val_accuracy: 0.9992 - val_loss: 0.0589 - learning_rate: 0.0021\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0019637327864641084.\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0573 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 0.0020\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0018503980121747014.\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9998 - loss: 0.0575 - val_accuracy: 0.9992 - val_loss: 0.0584 - learning_rate: 0.0019\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0017349047672208342.\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9996 - loss: 0.0573 - val_accuracy: 0.9992 - val_loss: 0.0573 - learning_rate: 0.0017\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.001617965105863049.\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9998 - loss: 0.0571 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 0.0016\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0015003.\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 0.0015\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.001382634894136951.\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 0.0014\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.001265695232779166.\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 174ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0581 - learning_rate: 0.0013\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0011502019878252988.\n",
            "Epoch 24/150\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 218ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0584 - learning_rate: 0.0012\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0010368672135358914.\n",
            "Epoch 25/150\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 129ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0577 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0009263896564820749.\n",
            "Epoch 26/150\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0578 - learning_rate: 9.2639e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008194504475406018.\n",
            "Epoch 27/150\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 8.1945e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0007167089024954917.\n",
            "Epoch 28/150\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 7.1671e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0006187984571369782.\n",
            "Epoch 29/150\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.1880e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0005263227619192238.\n",
            "Epoch 30/150\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 5.2632e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0004398519602545348.\n",
            "Epoch 31/150\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 156ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 4.3985e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00035991917338963365.\n",
            "Epoch 32/150\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 240ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 3.5992e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.00028701721353589153.\n",
            "Epoch 33/150\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 2.8702e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.000221595545518168.\n",
            "Epoch 34/150\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 2.2160e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.00016405751567470485.\n",
            "Epoch 35/150\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 182ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 1.6406e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.00011475786509282328.\n",
            "Epoch 36/150\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 1.1476e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.400054251215825e-05.\n",
            "Epoch 37/150\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 7.4001e-05\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 4.203683037960447e-05.\n",
            "Epoch 38/150\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 4.2037e-05\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 1.9063795609472052e-05.\n",
            "Epoch 39/150\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 182ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 1.9064e-05\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 5.223074600427993e-06.\n",
            "Epoch 40/150\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 203ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 5.2231e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 41/150\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9998 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 42/150\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 43/150\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 44/150\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 45/150\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 46/150\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 129ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 47/150\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 189ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 48/150\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 205ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 49/150\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 50/150\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 51/150\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 52/150\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 53/150\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 54/150\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 55/150\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 154ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 56/150\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 245ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 57/150\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 58/150\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 59/150\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 60/150\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 61/150\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 62/150\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 63/150\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 162ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 64/150\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 209ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 65/150\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 66/150\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9998 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 67/150\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 68/150\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 69/150\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 70/150\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 71/150\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 72/150\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 171ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 73/150\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 231ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 74/150\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 75/150\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 76/150\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 77/150\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 78/150\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 79/150\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 80/150\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 139ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 81/150\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 217ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 82/150\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 144ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 83/150\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 84/150\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 85/150\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 185ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 86/150\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 87/150\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 88/150\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 89/150\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 189ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 90/150\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 177ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 91/150\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 92/150\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 93/150\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 94/150\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 95/150\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 250ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 96/150\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 97/150\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 202ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 98/150\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 186ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 99/150\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 100/150\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.99922\n",
            "10/10 - 4s - 427ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 101/150\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 138ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 102/150\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 103/150\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 187ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 104/150\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 202ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 105/150\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 106/150\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 107/150\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 108/150\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 109/150\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 110/150\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 111/150\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 160ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 112/150\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 232ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 113/150\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 114/150\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 115/150\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 116/150\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 117/150\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 118/150\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9998 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 119/150\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 151ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 120/150\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 248ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 121/150\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 147ms/step - accuracy: 0.9998 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 122/150\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 123/150\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 124/150\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 129ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 125/150\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 126/150\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 127/150\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 159ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 128/150\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 254ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 129/150\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 130/150\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 131/150\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 132/150\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 133/150\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 134/150\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 135/150\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 145ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 136/150\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 264ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 137/150\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 138/150\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 139/150\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 140/150\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 141/150\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 142/150\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 143/150\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 164ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 144/150\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 208ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 145/150\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0565 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 146/150\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 147/150\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9998 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 148/150\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 149/150\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 150/150\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0566 - val_accuracy: 0.9992 - val_loss: 0.0586 - learning_rate: 6.0000e-07\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "Test accuracy after 150 epochs → 0.995000\n",
            "\n",
            "================================================================================\n",
            "Training for 300 epochs...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99609, saving model to /content/job/model_300.keras\n",
            "10/10 - 5s - 480ms/step - accuracy: 0.8637 - loss: 0.3767 - val_accuracy: 0.9961 - val_loss: 0.1071 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002995376925399572.\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.99609 to 0.99844, saving model to /content/job/model_300.keras\n",
            "10/10 - 1s - 149ms/step - accuracy: 0.9924 - loss: 0.0942 - val_accuracy: 0.9984 - val_loss: 0.0685 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0029815362043905283.\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 135ms/step - accuracy: 0.9975 - loss: 0.0699 - val_accuracy: 0.9977 - val_loss: 0.0675 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0029585631696203954.\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 136ms/step - accuracy: 0.9986 - loss: 0.0667 - val_accuracy: 0.9977 - val_loss: 0.0637 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.002926599457487842.\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9986 - loss: 0.0648 - val_accuracy: 0.9977 - val_loss: 0.0634 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0028858421349071766.\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 134ms/step - accuracy: 0.9990 - loss: 0.0629 - val_accuracy: 0.9977 - val_loss: 0.0628 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002836542484325295.\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.99844\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9988 - loss: 0.0618 - val_accuracy: 0.9984 - val_loss: 0.0617 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0027790044544818322.\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.99844\n",
            "10/10 - 2s - 195ms/step - accuracy: 0.9992 - loss: 0.0612 - val_accuracy: 0.9977 - val_loss: 0.0610 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0027135827864641087.\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.99844\n",
            "10/10 - 2s - 196ms/step - accuracy: 0.9992 - loss: 0.0603 - val_accuracy: 0.9984 - val_loss: 0.0605 - learning_rate: 0.0027\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002640680826610367.\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.99844 to 0.99922, saving model to /content/job/model_300.keras\n",
            "10/10 - 1s - 149ms/step - accuracy: 0.9990 - loss: 0.0600 - val_accuracy: 0.9992 - val_loss: 0.0599 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002560748039745465.\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 0.9990 - loss: 0.0593 - val_accuracy: 0.9992 - val_loss: 0.0594 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.002474277238080777.\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 146ms/step - accuracy: 0.9992 - loss: 0.0594 - val_accuracy: 0.9992 - val_loss: 0.0597 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0023818015428630217.\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9992 - loss: 0.0588 - val_accuracy: 0.9992 - val_loss: 0.0593 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022838910975045085.\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9996 - loss: 0.0586 - val_accuracy: 0.9992 - val_loss: 0.0588 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0021811495524593984.\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9996 - loss: 0.0581 - val_accuracy: 0.9992 - val_loss: 0.0589 - learning_rate: 0.0022\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0020742103435179254.\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 187ms/step - accuracy: 0.9996 - loss: 0.0583 - val_accuracy: 0.9992 - val_loss: 0.0594 - learning_rate: 0.0021\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0019637327864641084.\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 185ms/step - accuracy: 0.9998 - loss: 0.0577 - val_accuracy: 0.9992 - val_loss: 0.0587 - learning_rate: 0.0020\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0018503980121747014.\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0577 - val_accuracy: 0.9992 - val_loss: 0.0583 - learning_rate: 0.0019\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0017349047672208342.\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9998 - loss: 0.0576 - val_accuracy: 0.9977 - val_loss: 0.0600 - learning_rate: 0.0017\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.001617965105863049.\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0576 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 0.0016\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0015003.\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0572 - val_accuracy: 0.9992 - val_loss: 0.0585 - learning_rate: 0.0015\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.001382634894136951.\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0572 - val_accuracy: 0.9984 - val_loss: 0.0591 - learning_rate: 0.0014\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.001265695232779166.\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0571 - val_accuracy: 0.9992 - val_loss: 0.0593 - learning_rate: 0.0013\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0011502019878252988.\n",
            "Epoch 24/300\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0594 - learning_rate: 0.0012\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0010368672135358914.\n",
            "Epoch 25/300\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 213ms/step - accuracy: 0.9998 - loss: 0.0573 - val_accuracy: 0.9977 - val_loss: 0.0603 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0009263896564820749.\n",
            "Epoch 26/300\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 156ms/step - accuracy: 0.9998 - loss: 0.0571 - val_accuracy: 0.9984 - val_loss: 0.0597 - learning_rate: 9.2639e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008194504475406018.\n",
            "Epoch 27/300\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9984 - val_loss: 0.0595 - learning_rate: 8.1945e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0007167089024954917.\n",
            "Epoch 28/300\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9984 - val_loss: 0.0597 - learning_rate: 7.1671e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0006187984571369782.\n",
            "Epoch 29/300\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 188ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9984 - val_loss: 0.0597 - learning_rate: 6.1880e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0005263227619192238.\n",
            "Epoch 30/300\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9984 - val_loss: 0.0594 - learning_rate: 5.2632e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0004398519602545348.\n",
            "Epoch 31/300\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 4.3985e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00035991917338963365.\n",
            "Epoch 32/300\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0587 - learning_rate: 3.5992e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.00028701721353589153.\n",
            "Epoch 33/300\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 191ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0589 - learning_rate: 2.8702e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.000221595545518168.\n",
            "Epoch 34/300\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 200ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 2.2160e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.00016405751567470485.\n",
            "Epoch 35/300\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 1.6406e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.00011475786509282328.\n",
            "Epoch 36/300\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 1.1476e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.400054251215825e-05.\n",
            "Epoch 37/300\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 139ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 7.4001e-05\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 4.203683037960447e-05.\n",
            "Epoch 38/300\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 140ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 4.2037e-05\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 1.9063795609472052e-05.\n",
            "Epoch 39/300\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 1.9064e-05\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 5.223074600427993e-06.\n",
            "Epoch 40/300\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 5.2231e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 41/300\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 182ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 42/300\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 184ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 43/300\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 44/300\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 256ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 45/300\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 46/300\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 47/300\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 48/300\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 49/300\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 208ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 50/300\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 166ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 51/300\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 52/300\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 53/300\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 54/300\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 55/300\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 56/300\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 57/300\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 158ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 58/300\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 247ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 59/300\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 60/300\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 61/300\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 62/300\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 63/300\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 64/300\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 65/300\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 158ms/step - accuracy: 0.9996 - loss: 0.0573 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 66/300\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 220ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 67/300\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 68/300\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 69/300\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 70/300\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 256ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 71/300\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 72/300\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 73/300\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 177ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 74/300\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 192ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 75/300\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 76/300\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 77/300\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 78/300\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 79/300\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 80/300\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 81/300\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 82/300\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 203ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 83/300\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 185ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 84/300\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 85/300\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 185ms/step - accuracy: 0.9998 - loss: 0.0571 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 86/300\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 87/300\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 139ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 88/300\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 89/300\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 90/300\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 212ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 91/300\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 157ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 92/300\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 93/300\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 94/300\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 95/300\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 96/300\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 97/300\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 98/300\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 152ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 99/300\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 248ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 100/300\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 101: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 101/300\n",
            "\n",
            "Epoch 101: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 102: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 102/300\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 197ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 103: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 103/300\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 195ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 104: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 104/300\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 105: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 105/300\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 154ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 106: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 106/300\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 248ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 107: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 107/300\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 108: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 108/300\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 109: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 109/300\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 110: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 110/300\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 111: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 111/300\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 112: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 112/300\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 113: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 113/300\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 160ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 114: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 114/300\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 208ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 115: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 115/300\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 116: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 116/300\n",
            "\n",
            "Epoch 116: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 117: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 117/300\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 118: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 118/300\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 119: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 119/300\n",
            "\n",
            "Epoch 119: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 120: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 120/300\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 121: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 121/300\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 138ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 122: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 122/300\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 188ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 123: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 123/300\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 177ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 124: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 124/300\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 125: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 125/300\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 126: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 126/300\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 127: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 127/300\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 128: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 128/300\n",
            "\n",
            "Epoch 128: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 129: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 129/300\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 130: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 130/300\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 131: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 131/300\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 205ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 132: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 132/300\n",
            "\n",
            "Epoch 132: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 183ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 133: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 133/300\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 134: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 134/300\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 135: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 135/300\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 136: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 136/300\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 137: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 137/300\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 138: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 138/300\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 139: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 139/300\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 171ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 140: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 140/300\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 221ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 141: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 141/300\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 142: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 142/300\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 143: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 143/300\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 144: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 144/300\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9998 - loss: 0.0571 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 145: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 145/300\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 146: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 146/300\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 147: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 147/300\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 155ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 148: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 148/300\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 244ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 149: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 149/300\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 150: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 150/300\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0590 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 151: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 151/300\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 147ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 152: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 152/300\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 153: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 153/300\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 154: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 154/300\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 189ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 155: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 155/300\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 205ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 156: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 156/300\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 168ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 157: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 157/300\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 158: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 158/300\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 159: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 159/300\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 160: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 160/300\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 161: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 161/300\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 162: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 162/300\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 163: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 163/300\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 148ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 164: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 164/300\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 219ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 165: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 165/300\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 166: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 166/300\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 167: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 167/300\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 168: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 168/300\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 169: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 169/300\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 170: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 170/300\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 171: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 171/300\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 172: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 172/300\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 175ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 173: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 173/300\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 219ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 174: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 174/300\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 175: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 175/300\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 176: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 176/300\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 177: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 177/300\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 178: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 178/300\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 179: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 179/300\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 180: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 180/300\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 173ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 181: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 181/300\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 222ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 182: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 182/300\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 183: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 183/300\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 184: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 184/300\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 185: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 185/300\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 186: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 186/300\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 187: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 187/300\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 139ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 188: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 188/300\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 166ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 189: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 189/300\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 229ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 190: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 190/300\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 191: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 191/300\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 192: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 192/300\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 193: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 193/300\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 194: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 194/300\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 195: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 195/300\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 196: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 196/300\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 160ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 197: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 197/300\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 240ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 198: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 198/300\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 199: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 199/300\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 200: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 200/300\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 201: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 201/300\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 202: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 202/300\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 203: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 203/300\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 147ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 204: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 204/300\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 162ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 205: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 205/300\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 204ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 206: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 206/300\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 207: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 207/300\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 208: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 208/300\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 209: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 209/300\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 210: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 210/300\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 190ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 211: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 211/300\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 138ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 212: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 212/300\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 159ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 213: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 213/300\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 248ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 214: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 214/300\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 215: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 215/300\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 216: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 216/300\n",
            "\n",
            "Epoch 216: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 262ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 217: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 217/300\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 218: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 218/300\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 219: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 219/300\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 165ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 220: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 220/300\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 237ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 221: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 221/300\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 222: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 222/300\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 223: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 223/300\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9996 - loss: 0.0572 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 224: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 224/300\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 225: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 225/300\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 226: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 226/300\n",
            "\n",
            "Epoch 226: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 227: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 227/300\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 164ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 228: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 228/300\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 238ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 229: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 229/300\n",
            "\n",
            "Epoch 229: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 230: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 230/300\n",
            "\n",
            "Epoch 230: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 231: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 231/300\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 232: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 232/300\n",
            "\n",
            "Epoch 232: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 233: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 233/300\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 234: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 234/300\n",
            "\n",
            "Epoch 234: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 235: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 235/300\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 193ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 236: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 236/300\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 205ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 237: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 237/300\n",
            "\n",
            "Epoch 237: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 238: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 238/300\n",
            "\n",
            "Epoch 238: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 239: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 239/300\n",
            "\n",
            "Epoch 239: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 240: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 240/300\n",
            "\n",
            "Epoch 240: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 241: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 241/300\n",
            "\n",
            "Epoch 241: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 242: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 242/300\n",
            "\n",
            "Epoch 242: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 243: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 243/300\n",
            "\n",
            "Epoch 243: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 202ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 244: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 244/300\n",
            "\n",
            "Epoch 244: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 181ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 245: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 245/300\n",
            "\n",
            "Epoch 245: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 246: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 246/300\n",
            "\n",
            "Epoch 246: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 247: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 247/300\n",
            "\n",
            "Epoch 247: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 248: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 248/300\n",
            "\n",
            "Epoch 248: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 249: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 249/300\n",
            "\n",
            "Epoch 249: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 250: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 250/300\n",
            "\n",
            "Epoch 250: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 251: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 251/300\n",
            "\n",
            "Epoch 251: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 139ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 252: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 252/300\n",
            "\n",
            "Epoch 252: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 273ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 253: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 253/300\n",
            "\n",
            "Epoch 253: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 254: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 254/300\n",
            "\n",
            "Epoch 254: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 255: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 255/300\n",
            "\n",
            "Epoch 255: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 256: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 256/300\n",
            "\n",
            "Epoch 256: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 151ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 257: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 257/300\n",
            "\n",
            "Epoch 257: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 212ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 258: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 258/300\n",
            "\n",
            "Epoch 258: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 259: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 259/300\n",
            "\n",
            "Epoch 259: val_accuracy did not improve from 0.99922\n",
            "10/10 - 3s - 283ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 260: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 260/300\n",
            "\n",
            "Epoch 260: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 261: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 261/300\n",
            "\n",
            "Epoch 261: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 262: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 262/300\n",
            "\n",
            "Epoch 262: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 263: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 263/300\n",
            "\n",
            "Epoch 263: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 264: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 264/300\n",
            "\n",
            "Epoch 264: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 265: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 265/300\n",
            "\n",
            "Epoch 265: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 266: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 266/300\n",
            "\n",
            "Epoch 266: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 148ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 267: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 267/300\n",
            "\n",
            "Epoch 267: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 217ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 268: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 268/300\n",
            "\n",
            "Epoch 268: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 269: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 269/300\n",
            "\n",
            "Epoch 269: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 270: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 270/300\n",
            "\n",
            "Epoch 270: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 271: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 271/300\n",
            "\n",
            "Epoch 271: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 272: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 272/300\n",
            "\n",
            "Epoch 272: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 273: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 273/300\n",
            "\n",
            "Epoch 273: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 130ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 274: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 274/300\n",
            "\n",
            "Epoch 274: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 275: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 275/300\n",
            "\n",
            "Epoch 275: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 165ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 276: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 276/300\n",
            "\n",
            "Epoch 276: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 227ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 277: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 277/300\n",
            "\n",
            "Epoch 277: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 278: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 278/300\n",
            "\n",
            "Epoch 278: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 279: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 279/300\n",
            "\n",
            "Epoch 279: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 191ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 280: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 280/300\n",
            "\n",
            "Epoch 280: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 281: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 281/300\n",
            "\n",
            "Epoch 281: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 135ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 282: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 282/300\n",
            "\n",
            "Epoch 282: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 283: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 283/300\n",
            "\n",
            "Epoch 283: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 201ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 284: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 284/300\n",
            "\n",
            "Epoch 284: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 188ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 285: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 285/300\n",
            "\n",
            "Epoch 285: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 286: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 286/300\n",
            "\n",
            "Epoch 286: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 287: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 287/300\n",
            "\n",
            "Epoch 287: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 136ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 288: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 288/300\n",
            "\n",
            "Epoch 288: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 289: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 289/300\n",
            "\n",
            "Epoch 289: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 290: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 290/300\n",
            "\n",
            "Epoch 290: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 131ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 291: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 291/300\n",
            "\n",
            "Epoch 291: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 177ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 292: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 292/300\n",
            "\n",
            "Epoch 292: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 219ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 293: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 293/300\n",
            "\n",
            "Epoch 293: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 294: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 294/300\n",
            "\n",
            "Epoch 294: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 134ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 295: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 295/300\n",
            "\n",
            "Epoch 295: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 132ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 296: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 296/300\n",
            "\n",
            "Epoch 296: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 133ms/step - accuracy: 1.0000 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 297: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 297/300\n",
            "\n",
            "Epoch 297: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 139ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 298: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 298/300\n",
            "\n",
            "Epoch 298: val_accuracy did not improve from 0.99922\n",
            "10/10 - 1s - 137ms/step - accuracy: 0.9998 - loss: 0.0569 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 299: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 299/300\n",
            "\n",
            "Epoch 299: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 162ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 300: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 300/300\n",
            "\n",
            "Epoch 300: val_accuracy did not improve from 0.99922\n",
            "10/10 - 2s - 241ms/step - accuracy: 1.0000 - loss: 0.0568 - val_accuracy: 0.9992 - val_loss: 0.0591 - learning_rate: 6.0000e-07\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "Test accuracy after 300 epochs → 0.995000\n",
            "Saved results JSON: /content/job/acc_results.json\n",
            "Saved accuracy plot: /content/job/accuracy_vs_epochs.png\n"
          ]
        }
      ],
      "source": [
        "!pip install -q xgboost\n",
        "\n",
        "import os, re, json, math, itertools, random, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "\n",
        "CSV_PATH = \"/content/final_ml_dataset_8000.csv\"\n",
        "TARGET = \"self_harm_flag\"\n",
        "VAL_SIZE = 0.20\n",
        "SEED = 42\n",
        "\n",
        "HIDDEN_SIZES = [512, 256, 128]\n",
        "DROPOUT_RATE = 0.10\n",
        "LABEL_SMOOTH = 0.02\n",
        "MAX_CROSS_PAIRS = 20\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "INITIAL_LR = 3e-3\n",
        "SAVE_DIR = \"/content/job\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "EPOCH_BUDGETS = [15, 150, 300]\n",
        "\n",
        "RESULTS_JSON = os.path.join(SAVE_DIR, \"acc_results.json\")\n",
        "ACCURACY_PNG = os.path.join(SAVE_DIR, \"accuracy_vs_epochs.png\")\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "print(\"Mixed precision enabled!\")\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Strategy replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "def is_id_like(n):\n",
        "    n = str(n).lower().strip()\n",
        "    return n == \"id\" or n.endswith(\"_id\") or n.startswith(\"id_\")\n",
        "\n",
        "def add_datetime_parts(df, target):\n",
        "    df = df.copy()\n",
        "    dtcols = []\n",
        "    for c in df.columns:\n",
        "        if c == target: continue\n",
        "        if df[c].dtype == object:\n",
        "            try:\n",
        "                df[c] = pd.to_datetime(df[c], errors=\"raise\")\n",
        "                dtcols.append(c)\n",
        "            except:\n",
        "                pass\n",
        "        elif np.issubdtype(df[c].dtype, np.datetime64):\n",
        "            dtcols.append(c)\n",
        "    for c in dtcols:\n",
        "        df[c+\"_year\"]  = df[c].dt.year\n",
        "        df[c+\"_month\"] = df[c].dt.month\n",
        "        df[c+\"_day\"]   = df[c].dt.day\n",
        "        df[c+\"_hour\"]  = df[c].dt.hour\n",
        "        df[c+\"_dow\"]   = df[c].dt.dayofweek\n",
        "        df.drop(columns=[c], inplace=True)\n",
        "    return df\n",
        "\n",
        "def auto_feature_crosses(Xdf, max_pairs=20):\n",
        "    nums = Xdf.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if len(nums) < 2:\n",
        "        return Xdf, []\n",
        "    vari = Xdf[nums].var().sort_values(ascending=False)\n",
        "    tops = vari.index[:max_pairs+2]\n",
        "    pairs = list(itertools.combinations(tops, 2))[:max_pairs]\n",
        "    for a, b in pairs:\n",
        "        Xdf[f\"{a}*{b}\"] = Xdf[a]*Xdf[b]\n",
        "    return Xdf, pairs\n",
        "\n",
        "def se_block(x, ratio=8, name=\"se\"):\n",
        "    channels = int(x.shape[-1])\n",
        "    s = layers.Reshape((1, channels), name=f\"{name}_reshape_in\")(x)\n",
        "    s = layers.GlobalAveragePooling1D(name=f\"{name}_gap\")(s)\n",
        "    s = layers.Dense(max(1, channels // ratio), activation=\"relu\", name=f\"{name}_fc1\")(s)\n",
        "    s = layers.Dense(channels, activation=\"sigmoid\", name=f\"{name}_fc2\")(s)\n",
        "    s = layers.Reshape((channels,), name=f\"{name}_reshape_out\")(s)\n",
        "    return layers.Multiply(name=f\"{name}_scale\")([x, s])\n",
        "\n",
        "def make_cosine_lr_fn(initial_lr, decay_epochs=40, alpha=0.0002):\n",
        "    def lr_fn(epoch):\n",
        "        t = min(epoch, decay_epochs)\n",
        "        cos_val = 0.5 * (1 + math.cos(math.pi * t / decay_epochs))\n",
        "        lr = initial_lr * (alpha + (1 - alpha) * cos_val)\n",
        "        return lr\n",
        "    return lr_fn\n",
        "\n",
        "print(\"Loading:\", CSV_PATH)\n",
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "\n",
        "df = df.drop(columns=[c for c in df.columns if is_id_like(c)], errors=\"ignore\")\n",
        "\n",
        "nunique = df.nunique(dropna=False)\n",
        "df = df.drop(columns=nunique[nunique <= 1].index.tolist())\n",
        "\n",
        "df = add_datetime_parts(df, TARGET)\n",
        "\n",
        "if TARGET not in df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET}' not found in dataset\")\n",
        "\n",
        "y_raw = df[TARGET].values\n",
        "classes = np.unique(y_raw)\n",
        "class_map = {str(c): i for i, c in enumerate(classes)}\n",
        "y = np.array([class_map[str(v)] for v in y_raw], dtype=int)\n",
        "\n",
        "X = df.drop(columns=[TARGET]).copy()\n",
        "\n",
        "for c in X.columns:\n",
        "    if X[c].dtype == object:\n",
        "        _, inv = np.unique(X[c].astype(str), return_inverse=True)\n",
        "        X[c] = inv.astype(np.float32)\n",
        "\n",
        "X, used_pairs = auto_feature_crosses(X, MAX_CROSS_PAIRS)\n",
        "print(\"Added feature crosses:\", used_pairs)\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X.values, y, test_size=VAL_SIZE, random_state=SEED, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=VAL_SIZE, random_state=SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(np.float32))\n",
        "X_val   = scaler.transform(X_val.astype(np.float32))\n",
        "X_test  = scaler.transform(X_test.astype(np.float32))\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(classes)\n",
        "print(\"Input dim:\", input_dim, \"Num classes:\", num_classes)\n",
        "\n",
        "def build_widedeep():\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    wide_logits = layers.Dense(num_classes)(inputs)\n",
        "\n",
        "    x = inputs\n",
        "    for i, h in enumerate(HIDDEN_SIZES, 1):\n",
        "        x = layers.Dense(h, kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.Activation(\"gelu\")(x)\n",
        "        x = layers.Dropout(DROPOUT_RATE)(x)\n",
        "        x = se_block(x, ratio=8, name=f\"se_{i}\")\n",
        "\n",
        "    deep_logits = layers.Dense(num_classes)(x)\n",
        "    combined = layers.Add()([wide_logits, deep_logits])\n",
        "    out = layers.Activation(\"softmax\", dtype=\"float32\")(combined)\n",
        "    return keras.Model(inputs, out)\n",
        "\n",
        "results = {}\n",
        "\n",
        "for epochs in EPOCH_BUDGETS:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Training for {epochs} epochs...\")\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = build_widedeep()\n",
        "        opt = keras.optimizers.Adam(learning_rate=INITIAL_LR)\n",
        "        model.compile(\n",
        "            optimizer=opt,\n",
        "            loss=keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTH),\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "    y_train_oh = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_val_oh   = keras.utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    lr_schedule = make_cosine_lr_fn(INITIAL_LR)\n",
        "    cbs = [\n",
        "        callbacks.ModelCheckpoint(\n",
        "            os.path.join(SAVE_DIR, f\"model_{epochs}.keras\"),\n",
        "            save_best_only=True,\n",
        "            monitor=\"val_accuracy\",\n",
        "            mode=\"max\",\n",
        "            verbose=1,\n",
        "        ),\n",
        "        callbacks.LearningRateScheduler(lambda ep: lr_schedule(ep), verbose=1)\n",
        "    ]\n",
        "\n",
        "    hist = model.fit(\n",
        "        X_train, y_train_oh,\n",
        "        validation_data=(X_val, y_val_oh),\n",
        "        epochs=epochs,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=cbs,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    preds = model.predict(X_test).argmax(axis=1)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "\n",
        "    print(f\"Test accuracy after {epochs} epochs → {acc:.6f}\")\n",
        "    results[epochs] = float(acc)\n",
        "\n",
        "with open(RESULTS_JSON, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "x = sorted(results.keys())\n",
        "y = [results[k] for k in x]\n",
        "plt.plot(x, y, marker=\"o\")\n",
        "for a, b in zip(x, y):\n",
        "    plt.text(a, b, f\"{b:.4f}\", ha=\"center\", va=\"bottom\")\n",
        "plt.title(\"SE + WideDeep Accuracy vs Epoch Budgets\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.savefig(ACCURACY_PNG, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved results JSON:\", RESULTS_JSON)\n",
        "print(\"Saved accuracy plot:\", ACCURACY_PNG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfZutj38N2BZ",
        "outputId": "75924334-61ec-46dc-8fa6-7c62ca0a759b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2361702639.py:90: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  signup_date = (datetime.utcnow() - timedelta(days=signup_days_ago)).date().isoformat()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Users created: (50000, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2361702639.py:54: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  now = datetime.utcnow()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated tweets for 5000 users ...\n",
            "Generated tweets for 10000 users ...\n",
            "Generated tweets for 15000 users ...\n",
            "Generated tweets for 20000 users ...\n",
            "Generated tweets for 25000 users ...\n",
            "Generated tweets for 30000 users ...\n",
            "Generated tweets for 35000 users ...\n",
            "Generated tweets for 40000 users ...\n",
            "Generated tweets for 45000 users ...\n",
            "Generated tweets for 50000 users ...\n",
            "Generated tweets: (824699, 8)\n",
            "Saved: /content/synthetic_users_50000.csv /content/synthetic_tweets_50000_users.csv\n",
            "Total users: 50000 Total tweets: 824699\n"
          ]
        }
      ],
      "source": [
        "import random, math, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import gc\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "N_USERS = 50000\n",
        "MIN_TWEETS_PER_USER = 8\n",
        "MAX_TWEETS_PER_USER = 25\n",
        "TWEET_WINDOW_DAYS = 730\n",
        "SELF_HARM_PREVALENCE = 0.12\n",
        "\n",
        "stress_keywords = [\n",
        "    \"stress\", \"anxiety\", \"depressed\", \"depression\", \"tired\", \"hopeless\", \"alone\",\n",
        "    \"worthless\", \"panic\", \"overwhelmed\", \"exhausted\", \"helpless\", \"sad\", \"numb\",\n",
        "    \"empty\", \"hurt\", \"broken\", \"struggle\", \"suicidal\", \"give up\"\n",
        "]\n",
        "\n",
        "neutral_words = [\n",
        "    \"work\", \"coffee\", \"movie\", \"football\", \"game\", \"music\", \"lecture\", \"project\",\n",
        "    \"lunch\", \"travel\", \"happy\", \"love\", \"family\", \"friend\", \"weather\", \"tech\",\n",
        "    \"code\", \"study\", \"shopping\", \"birthday\"\n",
        "]\n",
        "\n",
        "positive_phrases = [\n",
        "    \"Had a great day!\", \"Feeling good today.\", \"Loved the movie I watched.\",\n",
        "    \"Excited for the weekend.\", \"Grateful for my friends.\"\n",
        "]\n",
        "\n",
        "negative_phrases = [\n",
        "    \"This day has been rough.\", \"Feeling down.\", \"Really tired of everything.\",\n",
        "    \"Not my day.\", \"Things are hard right now.\"\n",
        "]\n",
        "\n",
        "suffixes = [\"#life\", \"#mood\", \"#work\", \":-(\", \":)\"]\n",
        "\n",
        "templates = [\n",
        "    \"{middle}\", \"{prefix} {middle}\", \"{middle} {suffix}\", \"{prefix} {middle} {suffix}\"\n",
        "]\n",
        "\n",
        "def rand_date_within(days_back=TWEET_WINDOW_DAYS):\n",
        "    now = datetime.utcnow()\n",
        "    d = random.randint(0, days_back)\n",
        "    s = random.randint(0, 86399)\n",
        "    return (now - timedelta(days=d, seconds=s)).isoformat() + \"Z\"\n",
        "\n",
        "def make_tweet_text(is_at_risk):\n",
        "    parts = []\n",
        "    stress_prob = 0.30 if is_at_risk else 0.06\n",
        "    negative_prob = 0.28 if is_at_risk else 0.08\n",
        "    positive_prob = 0.08 if is_at_risk else 0.30\n",
        "\n",
        "    if random.random() < 0.35:\n",
        "        prefix = random.choice([\"FYI\", \"Update:\", \"Note:\", \"\"])\n",
        "    else:\n",
        "        prefix = \"\"\n",
        "    mid_roll = random.random()\n",
        "    if mid_roll < stress_prob:\n",
        "        kw = random.choice(stress_keywords)\n",
        "        addon = random.choice(negative_phrases) if random.random() < 0.6 else random.choice(neutral_words)\n",
        "        middle = f\"{kw} {addon}\"\n",
        "    elif mid_roll < stress_prob + negative_prob:\n",
        "        middle = random.choice(negative_phrases)\n",
        "    elif mid_roll < stress_prob + negative_prob + positive_prob:\n",
        "        middle = random.choice(positive_phrases)\n",
        "    else:\n",
        "        middle = f\"{random.choice(neutral_words)} {random.choice(neutral_words)}\"\n",
        "    suffix = random.choice(suffixes) if random.random() < 0.22 else \"\"\n",
        "    parts = [p for p in [prefix, middle, suffix] if p]\n",
        "    text = \" \".join(parts).strip()\n",
        "    return text[:280]\n",
        "\n",
        "users = []\n",
        "for uid in range(1, N_USERS+1):\n",
        "    self_harm_flag = int(np.random.choice([0,1], p=[1-SELF_HARM_PREVALENCE, SELF_HARM_PREVALENCE]))\n",
        "    signup_days_ago = random.randint(30, 3650)\n",
        "    signup_date = (datetime.utcnow() - timedelta(days=signup_days_ago)).date().isoformat()\n",
        "    followers = int(np.random.exponential(scale=40))\n",
        "    total_tweets_estimate = random.randint(20, 10000)\n",
        "    users.append({\n",
        "        \"user_id\": uid,\n",
        "        \"self_harm_flag\": self_harm_flag,\n",
        "        \"signup_date\": signup_date,\n",
        "        \"followers\": followers,\n",
        "        \"total_tweets_estimate\": total_tweets_estimate\n",
        "    })\n",
        "\n",
        "users_df = pd.DataFrame(users)\n",
        "print(\"Users created:\", users_df.shape)\n",
        "\n",
        "tweets_records = []\n",
        "tweet_id = 1\n",
        "total_estimated = 0\n",
        "for idx, row in users_df.iterrows():\n",
        "    uid = int(row.user_id)\n",
        "    is_at_risk = bool(row.self_harm_flag)\n",
        "    n_tweets = random.randint(MIN_TWEETS_PER_USER, MAX_TWEETS_PER_USER)\n",
        "    total_estimated += n_tweets\n",
        "    for _ in range(n_tweets):\n",
        "        tweets_records.append({\n",
        "            \"tweet_id\": tweet_id,\n",
        "            \"user_id\": uid,\n",
        "            \"created_at\": rand_date_within(),\n",
        "            \"text\": make_tweet_text(is_at_risk),\n",
        "            \"is_reply\": int(random.random() < 0.12),\n",
        "            \"is_retweet\": int(random.random() < 0.08),\n",
        "            \"like_count\": int(np.random.poisson(1.5)),\n",
        "            \"retweet_count\": int(np.random.poisson(0.4))\n",
        "        })\n",
        "        tweet_id += 1\n",
        "    if (idx+1) % 5000 == 0:\n",
        "        print(f\"Generated tweets for {idx+1} users ...\")\n",
        "\n",
        "tweets_df = pd.DataFrame(tweets_records)\n",
        "print(\"Generated tweets:\", tweets_df.shape)\n",
        "del tweets_records\n",
        "gc.collect()\n",
        "\n",
        "users_path = \"/content/synthetic_users_50000.csv\"\n",
        "tweets_path = \"/content/synthetic_tweets_50000_users.csv\"\n",
        "users_df.to_csv(users_path, index=False)\n",
        "tweets_df.to_csv(tweets_path, index=False)\n",
        "print(\"Saved:\", users_path, tweets_path)\n",
        "print(\"Total users:\", len(users_df), \"Total tweets:\", len(tweets_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "12GOGg6mxbdD",
        "outputId": "6e6aaa8c-bdda-4224-93a9-0e57648b82c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded users: (50000, 5) tweets: (824699, 8)\n",
            "Computing sentiment scores...\n",
            "Saved final ML dataset: /content/final_ml_dataset_50000.csv\n",
            "Final shape: (50000, 11)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"final_df\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14433,\n        \"min\": 1,\n        \"max\": 50000,\n        \"num_unique_values\": 50000,\n        \"samples\": [\n          33554,\n          9428,\n          200\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"self_harm_flag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"signup_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3621,\n        \"samples\": [\n          \"2023-04-29\",\n          \"2021-05-16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"followers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 0,\n        \"max\": 469,\n        \"num_unique_values\": 310,\n        \"samples\": [\n          270,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_tweets_estimate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2880,\n        \"min\": 20,\n        \"max\": 10000,\n        \"num_unique_values\": 9917,\n        \"samples\": [\n          3571,\n          3251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12718777408707863,\n        \"min\": -0.45099,\n        \"max\": 0.6582125,\n        \"num_unique_values\": 47644,\n        \"samples\": [\n          0.4146444444444445,\n          0.11908181818181816\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neg_tweet_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12211727033968567,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 154,\n        \"samples\": [\n          0.047619047619047616,\n          0.5833333333333334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stress_keywords_freq_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 18,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stress_keywords_freq_tweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 15,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"past_month_activity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet_activity_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0023568561786933727,\n        \"min\": 0.0,\n        \"max\": 0.1,\n        \"num_unique_values\": 11937,\n        \"samples\": [\n          0.00044612982377871963,\n          0.0002960331557134399\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "final_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a0925033-ed93-4d7c-a089-cc4cd1076684\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>self_harm_flag</th>\n",
              "      <th>signup_date</th>\n",
              "      <th>followers</th>\n",
              "      <th>total_tweets_estimate</th>\n",
              "      <th>avg_sentiment</th>\n",
              "      <th>neg_tweet_ratio</th>\n",
              "      <th>stress_keywords_freq_total</th>\n",
              "      <th>stress_keywords_freq_tweets</th>\n",
              "      <th>past_month_activity</th>\n",
              "      <th>tweet_activity_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-08-30</td>\n",
              "      <td>120</td>\n",
              "      <td>1844</td>\n",
              "      <td>0.299050</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-07-21</td>\n",
              "      <td>36</td>\n",
              "      <td>4526</td>\n",
              "      <td>0.146156</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-02-01</td>\n",
              "      <td>6</td>\n",
              "      <td>3677</td>\n",
              "      <td>0.348593</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-04-08</td>\n",
              "      <td>80</td>\n",
              "      <td>1699</td>\n",
              "      <td>0.289161</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2018-03-31</td>\n",
              "      <td>49</td>\n",
              "      <td>8955</td>\n",
              "      <td>0.225477</td>\n",
              "      <td>0.153846</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0925033-ed93-4d7c-a089-cc4cd1076684')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0925033-ed93-4d7c-a089-cc4cd1076684 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0925033-ed93-4d7c-a089-cc4cd1076684');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9f911030-4094-4227-bd74-2e2a7a924b5a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f911030-4094-4227-bd74-2e2a7a924b5a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9f911030-4094-4227-bd74-2e2a7a924b5a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   user_id  self_harm_flag signup_date  followers  total_tweets_estimate  \\\n",
              "0        1               0  2018-08-30        120                   1844   \n",
              "1        2               0  2025-07-21         36                   4526   \n",
              "2        3               0  2023-02-01          6                   3677   \n",
              "3        4               0  2024-04-08         80                   1699   \n",
              "4        5               0  2018-03-31         49                   8955   \n",
              "\n",
              "   avg_sentiment  neg_tweet_ratio  stress_keywords_freq_total  \\\n",
              "0       0.299050         0.083333                           1   \n",
              "1       0.146156         0.240000                           1   \n",
              "2       0.348593         0.285714                           3   \n",
              "3       0.289161         0.055556                           0   \n",
              "4       0.225477         0.153846                           1   \n",
              "\n",
              "   stress_keywords_freq_tweets  past_month_activity  tweet_activity_ratio  \n",
              "0                            1                    0              0.000000  \n",
              "1                            1                    0              0.000000  \n",
              "2                            3                    1              0.000272  \n",
              "3                            0                    1              0.000589  \n",
              "4                            1                    1              0.000112  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install -q vaderSentiment\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from datetime import timedelta\n",
        "\n",
        "users = pd.read_csv(\"/content/synthetic_users_50000.csv\")\n",
        "tweets = pd.read_csv(\"/content/synthetic_tweets_50000_users.csv\")\n",
        "print(\"Loaded users:\", users.shape, \"tweets:\", tweets.shape)\n",
        "\n",
        "tweets[\"created_at\"] = pd.to_datetime(tweets[\"created_at\"], errors=\"coerce\")\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def safe_sentiment(text):\n",
        "    try:\n",
        "        return analyzer.polarity_scores(str(text))[\"compound\"]\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "print(\"Computing sentiment scores...\")\n",
        "tweets[\"sentiment_score\"] = tweets[\"text\"].apply(safe_sentiment)\n",
        "\n",
        "avg_sentiment = tweets.groupby(\"user_id\")[\"sentiment_score\"].mean().reset_index()\n",
        "avg_sentiment.columns = [\"user_id\", \"avg_sentiment\"]\n",
        "\n",
        "tweets[\"is_negative\"] = tweets[\"sentiment_score\"] <= -0.05\n",
        "neg_tweet_ratio = tweets.groupby(\"user_id\")[\"is_negative\"].mean().reset_index()\n",
        "neg_tweet_ratio.columns = [\"user_id\", \"neg_tweet_ratio\"]\n",
        "\n",
        "stress_keywords = [\n",
        "    \"stress\", \"tired\", \"depressed\", \"anxiety\", \"worthless\",\n",
        "    \"panic\", \"alone\", \"sad\", \"hopeless\", \"fail\", \"overwhelmed\",\n",
        "    \"empty\", \"hurt\", \"struggle\", \"helpless\", \"broken\", \"give up\", \"suicidal\"\n",
        "]\n",
        "stress_keywords = [w.lower() for w in stress_keywords]\n",
        "\n",
        "def count_stress_words(text):\n",
        "    t = str(text).lower()\n",
        "    return sum(t.count(w) for w in stress_keywords)\n",
        "\n",
        "tweets[\"stress_word_count\"] = tweets[\"text\"].apply(count_stress_words)\n",
        "tweets[\"has_stress_word\"] = tweets[\"stress_word_count\"] > 0\n",
        "\n",
        "stress_keywords_total = tweets.groupby(\"user_id\")[\"stress_word_count\"].sum().reset_index()\n",
        "stress_keywords_total.columns = [\"user_id\", \"stress_keywords_freq_total\"]\n",
        "\n",
        "stress_keywords_tweetcount = tweets.groupby(\"user_id\")[\"has_stress_word\"].sum().reset_index()\n",
        "stress_keywords_tweetcount.columns = [\"user_id\", \"stress_keywords_freq_tweets\"]\n",
        "\n",
        "latest_time = tweets[\"created_at\"].max()\n",
        "cutoff_date = latest_time - timedelta(days=30)\n",
        "tweets[\"is_recent\"] = tweets[\"created_at\"] >= cutoff_date\n",
        "past_month_activity = tweets.groupby(\"user_id\")[\"is_recent\"].sum().reset_index()\n",
        "past_month_activity.columns = [\"user_id\", \"past_month_activity\"]\n",
        "\n",
        "from functools import reduce\n",
        "frames = [users, avg_sentiment, neg_tweet_ratio, stress_keywords_total, stress_keywords_tweetcount, past_month_activity]\n",
        "final_df = reduce(lambda left, right: pd.merge(left, right, on=\"user_id\", how=\"left\"), frames)\n",
        "\n",
        "final_df[\"avg_sentiment\"] = final_df[\"avg_sentiment\"].fillna(0.0)\n",
        "final_df[\"neg_tweet_ratio\"] = final_df[\"neg_tweet_ratio\"].fillna(0.0)\n",
        "final_df[\"stress_keywords_freq_total\"] = final_df[\"stress_keywords_freq_total\"].fillna(0).astype(int)\n",
        "final_df[\"stress_keywords_freq_tweets\"] = final_df[\"stress_keywords_freq_tweets\"].fillna(0).astype(int)\n",
        "final_df[\"past_month_activity\"] = final_df[\"past_month_activity\"].fillna(0).astype(int)\n",
        "\n",
        "final_df[\"tweet_activity_ratio\"] = final_df[\"past_month_activity\"] / final_df[\"total_tweets_estimate\"].replace(0, np.nan)\n",
        "final_df[\"tweet_activity_ratio\"] = final_df[\"tweet_activity_ratio\"].fillna(0.0)\n",
        "\n",
        "final_out = \"/content/final_ml_dataset_50000.csv\"\n",
        "final_df.to_csv(final_out, index=False)\n",
        "print(\"Saved final ML dataset:\", final_out)\n",
        "print(\"Final shape:\", final_df.shape)\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoGINUDdxr0C",
        "outputId": "c4c037ff-06a2-4dd3-e6d2-67f8dde9b123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.19.0\n",
            "GPUs: []\n",
            "Mixed precision enabled!\n",
            "Strategy replicas: 1\n",
            "Loading: /content/final_ml_dataset_50000.csv\n",
            "Loaded shape: (50000, 11)\n",
            "Feature crosses added: [('total_tweets_estimate', 'followers'), ('total_tweets_estimate', 'signup_date_day'), ('total_tweets_estimate', 'signup_date_month'), ('total_tweets_estimate', 'signup_date_year'), ('total_tweets_estimate', 'stress_keywords_freq_total'), ('total_tweets_estimate', 'signup_date_dow'), ('total_tweets_estimate', 'stress_keywords_freq_tweets'), ('total_tweets_estimate', 'past_month_activity'), ('total_tweets_estimate', 'avg_sentiment'), ('total_tweets_estimate', 'neg_tweet_ratio'), ('total_tweets_estimate', 'tweet_activity_ratio'), ('total_tweets_estimate', 'signup_date_hour'), ('followers', 'signup_date_day'), ('followers', 'signup_date_month'), ('followers', 'signup_date_year'), ('followers', 'stress_keywords_freq_total'), ('followers', 'signup_date_dow'), ('followers', 'stress_keywords_freq_tweets'), ('followers', 'past_month_activity'), ('followers', 'avg_sentiment')]\n",
            "Input dim: 33 Num classes: 2\n",
            "\n",
            "================================================================================\n",
            "Training for 10 epochs...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96763, saving model to /content/job/model_10.keras\n",
            "32/32 - 22s - 679ms/step - accuracy: 0.9201 - loss: 0.2631 - val_accuracy: 0.9676 - val_loss: 0.1370 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002995376925399572.\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.96763\n",
            "32/32 - 6s - 179ms/step - accuracy: 0.9637 - loss: 0.1458 - val_accuracy: 0.9671 - val_loss: 0.1343 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0029815362043905283.\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96763 to 0.96850, saving model to /content/job/model_10.keras\n",
            "32/32 - 7s - 218ms/step - accuracy: 0.9647 - loss: 0.1425 - val_accuracy: 0.9685 - val_loss: 0.1334 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0029585631696203954.\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96850 to 0.96900, saving model to /content/job/model_10.keras\n",
            "32/32 - 6s - 180ms/step - accuracy: 0.9654 - loss: 0.1410 - val_accuracy: 0.9690 - val_loss: 0.1335 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.002926599457487842.\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.96900\n",
            "32/32 - 7s - 209ms/step - accuracy: 0.9655 - loss: 0.1399 - val_accuracy: 0.9679 - val_loss: 0.1340 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0028858421349071766.\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96900\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9656 - loss: 0.1391 - val_accuracy: 0.9678 - val_loss: 0.1336 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002836542484325295.\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96900\n",
            "32/32 - 7s - 231ms/step - accuracy: 0.9660 - loss: 0.1381 - val_accuracy: 0.9686 - val_loss: 0.1341 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0027790044544818322.\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96900\n",
            "32/32 - 6s - 193ms/step - accuracy: 0.9666 - loss: 0.1373 - val_accuracy: 0.9680 - val_loss: 0.1338 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0027135827864641087.\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96900\n",
            "32/32 - 6s - 197ms/step - accuracy: 0.9664 - loss: 0.1362 - val_accuracy: 0.9672 - val_loss: 0.1341 - learning_rate: 0.0027\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002640680826610367.\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96900\n",
            "32/32 - 10s - 298ms/step - accuracy: 0.9672 - loss: 0.1350 - val_accuracy: 0.9682 - val_loss: 0.1353 - learning_rate: 0.0026\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step\n",
            "Test accuracy after 10 epochs → 0.962600\n",
            "\n",
            "================================================================================\n",
            "Training for 50 epochs...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96737, saving model to /content/job/model_50.keras\n",
            "32/32 - 8s - 260ms/step - accuracy: 0.9273 - loss: 0.2342 - val_accuracy: 0.9674 - val_loss: 0.1357 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002995376925399572.\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96737 to 0.96750, saving model to /content/job/model_50.keras\n",
            "32/32 - 8s - 245ms/step - accuracy: 0.9641 - loss: 0.1454 - val_accuracy: 0.9675 - val_loss: 0.1328 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0029815362043905283.\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96750 to 0.96838, saving model to /content/job/model_50.keras\n",
            "32/32 - 6s - 185ms/step - accuracy: 0.9650 - loss: 0.1422 - val_accuracy: 0.9684 - val_loss: 0.1331 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0029585631696203954.\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96838 to 0.96875, saving model to /content/job/model_50.keras\n",
            "32/32 - 7s - 219ms/step - accuracy: 0.9651 - loss: 0.1404 - val_accuracy: 0.9688 - val_loss: 0.1341 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.002926599457487842.\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96875 to 0.96900, saving model to /content/job/model_50.keras\n",
            "32/32 - 6s - 180ms/step - accuracy: 0.9655 - loss: 0.1397 - val_accuracy: 0.9690 - val_loss: 0.1335 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0028858421349071766.\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96900\n",
            "32/32 - 7s - 211ms/step - accuracy: 0.9657 - loss: 0.1385 - val_accuracy: 0.9690 - val_loss: 0.1335 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002836542484325295.\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.96900 to 0.96925, saving model to /content/job/model_50.keras\n",
            "32/32 - 6s - 181ms/step - accuracy: 0.9662 - loss: 0.1376 - val_accuracy: 0.9693 - val_loss: 0.1337 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0027790044544818322.\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9668 - loss: 0.1361 - val_accuracy: 0.9691 - val_loss: 0.1339 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0027135827864641087.\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 174ms/step - accuracy: 0.9666 - loss: 0.1357 - val_accuracy: 0.9693 - val_loss: 0.1347 - learning_rate: 0.0027\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002640680826610367.\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9675 - loss: 0.1339 - val_accuracy: 0.9693 - val_loss: 0.1354 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002560748039745465.\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 175ms/step - accuracy: 0.9681 - loss: 0.1329 - val_accuracy: 0.9679 - val_loss: 0.1364 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.002474277238080777.\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 211ms/step - accuracy: 0.9676 - loss: 0.1319 - val_accuracy: 0.9680 - val_loss: 0.1364 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0023818015428630217.\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9690 - loss: 0.1294 - val_accuracy: 0.9676 - val_loss: 0.1387 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022838910975045085.\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 213ms/step - accuracy: 0.9693 - loss: 0.1287 - val_accuracy: 0.9675 - val_loss: 0.1396 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0021811495524593984.\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9696 - loss: 0.1265 - val_accuracy: 0.9675 - val_loss: 0.1415 - learning_rate: 0.0022\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0020742103435179254.\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 211ms/step - accuracy: 0.9711 - loss: 0.1247 - val_accuracy: 0.9665 - val_loss: 0.1423 - learning_rate: 0.0021\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0019637327864641084.\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9719 - loss: 0.1217 - val_accuracy: 0.9666 - val_loss: 0.1436 - learning_rate: 0.0020\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0018503980121747014.\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 213ms/step - accuracy: 0.9735 - loss: 0.1188 - val_accuracy: 0.9656 - val_loss: 0.1482 - learning_rate: 0.0019\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0017349047672208342.\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 192ms/step - accuracy: 0.9746 - loss: 0.1169 - val_accuracy: 0.9651 - val_loss: 0.1496 - learning_rate: 0.0017\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.001617965105863049.\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9752 - loss: 0.1151 - val_accuracy: 0.9651 - val_loss: 0.1537 - learning_rate: 0.0016\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0015003.\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9767 - loss: 0.1118 - val_accuracy: 0.9647 - val_loss: 0.1548 - learning_rate: 0.0015\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.001382634894136951.\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9770 - loss: 0.1094 - val_accuracy: 0.9645 - val_loss: 0.1607 - learning_rate: 0.0014\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.001265695232779166.\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 179ms/step - accuracy: 0.9787 - loss: 0.1073 - val_accuracy: 0.9641 - val_loss: 0.1663 - learning_rate: 0.0013\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0011502019878252988.\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9793 - loss: 0.1055 - val_accuracy: 0.9647 - val_loss: 0.1631 - learning_rate: 0.0012\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0010368672135358914.\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9807 - loss: 0.1019 - val_accuracy: 0.9632 - val_loss: 0.1684 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0009263896564820749.\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 210ms/step - accuracy: 0.9809 - loss: 0.1002 - val_accuracy: 0.9606 - val_loss: 0.1752 - learning_rate: 9.2639e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008194504475406018.\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 182ms/step - accuracy: 0.9808 - loss: 0.1002 - val_accuracy: 0.9616 - val_loss: 0.1702 - learning_rate: 8.1945e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0007167089024954917.\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 207ms/step - accuracy: 0.9822 - loss: 0.0978 - val_accuracy: 0.9621 - val_loss: 0.1725 - learning_rate: 7.1671e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0006187984571369782.\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 183ms/step - accuracy: 0.9844 - loss: 0.0937 - val_accuracy: 0.9631 - val_loss: 0.1717 - learning_rate: 6.1880e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0005263227619192238.\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 210ms/step - accuracy: 0.9856 - loss: 0.0910 - val_accuracy: 0.9616 - val_loss: 0.1762 - learning_rate: 5.2632e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0004398519602545348.\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.96925\n",
            "32/32 - 9s - 289ms/step - accuracy: 0.9872 - loss: 0.0888 - val_accuracy: 0.9615 - val_loss: 0.1790 - learning_rate: 4.3985e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00035991917338963365.\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.96925\n",
            "32/32 - 8s - 256ms/step - accuracy: 0.9871 - loss: 0.0876 - val_accuracy: 0.9601 - val_loss: 0.1810 - learning_rate: 3.5992e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.00028701721353589153.\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 179ms/step - accuracy: 0.9882 - loss: 0.0856 - val_accuracy: 0.9588 - val_loss: 0.1805 - learning_rate: 2.8702e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.000221595545518168.\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 215ms/step - accuracy: 0.9883 - loss: 0.0847 - val_accuracy: 0.9584 - val_loss: 0.1835 - learning_rate: 2.2160e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.00016405751567470485.\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 199ms/step - accuracy: 0.9898 - loss: 0.0826 - val_accuracy: 0.9594 - val_loss: 0.1856 - learning_rate: 1.6406e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.00011475786509282328.\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 215ms/step - accuracy: 0.9888 - loss: 0.0835 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 1.1476e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.400054251215825e-05.\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9897 - loss: 0.0826 - val_accuracy: 0.9614 - val_loss: 0.1852 - learning_rate: 7.4001e-05\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 4.203683037960447e-05.\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 216ms/step - accuracy: 0.9905 - loss: 0.0811 - val_accuracy: 0.9615 - val_loss: 0.1852 - learning_rate: 4.2037e-05\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 1.9063795609472052e-05.\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9892 - loss: 0.0821 - val_accuracy: 0.9604 - val_loss: 0.1855 - learning_rate: 1.9064e-05\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 5.223074600427993e-06.\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 214ms/step - accuracy: 0.9896 - loss: 0.0819 - val_accuracy: 0.9600 - val_loss: 0.1856 - learning_rate: 5.2231e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9902 - loss: 0.0818 - val_accuracy: 0.9600 - val_loss: 0.1856 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 214ms/step - accuracy: 0.9905 - loss: 0.0820 - val_accuracy: 0.9600 - val_loss: 0.1856 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9895 - loss: 0.0817 - val_accuracy: 0.9600 - val_loss: 0.1856 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 214ms/step - accuracy: 0.9902 - loss: 0.0822 - val_accuracy: 0.9600 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9907 - loss: 0.0810 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 216ms/step - accuracy: 0.9908 - loss: 0.0807 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9901 - loss: 0.0819 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 213ms/step - accuracy: 0.9898 - loss: 0.0823 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96925\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9902 - loss: 0.0820 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96925\n",
            "32/32 - 7s - 217ms/step - accuracy: 0.9899 - loss: 0.0825 - val_accuracy: 0.9601 - val_loss: 0.1857 - learning_rate: 6.0000e-07\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Test accuracy after 50 epochs → 0.955200\n",
            "\n",
            "================================================================================\n",
            "Training for 100 epochs...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.003.\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96675, saving model to /content/job/model_100.keras\n",
            "32/32 - 10s - 316ms/step - accuracy: 0.9172 - loss: 0.2471 - val_accuracy: 0.9668 - val_loss: 0.1389 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.002995376925399572.\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96675 to 0.96775, saving model to /content/job/model_100.keras\n",
            "32/32 - 6s - 180ms/step - accuracy: 0.9640 - loss: 0.1463 - val_accuracy: 0.9678 - val_loss: 0.1344 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0029815362043905283.\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96775 to 0.96900, saving model to /content/job/model_100.keras\n",
            "32/32 - 7s - 218ms/step - accuracy: 0.9648 - loss: 0.1422 - val_accuracy: 0.9690 - val_loss: 0.1334 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0029585631696203954.\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96900 to 0.96950, saving model to /content/job/model_100.keras\n",
            "32/32 - 6s - 182ms/step - accuracy: 0.9657 - loss: 0.1408 - val_accuracy: 0.9695 - val_loss: 0.1332 - learning_rate: 0.0030\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.002926599457487842.\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.96950\n",
            "32/32 - 10s - 322ms/step - accuracy: 0.9659 - loss: 0.1397 - val_accuracy: 0.9695 - val_loss: 0.1331 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0028858421349071766.\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96950\n",
            "32/32 - 7s - 224ms/step - accuracy: 0.9663 - loss: 0.1388 - val_accuracy: 0.9693 - val_loss: 0.1330 - learning_rate: 0.0029\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.002836542484325295.\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.96950 to 0.96962, saving model to /content/job/model_100.keras\n",
            "32/32 - 6s - 192ms/step - accuracy: 0.9662 - loss: 0.1370 - val_accuracy: 0.9696 - val_loss: 0.1333 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0027790044544818322.\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 226ms/step - accuracy: 0.9662 - loss: 0.1360 - val_accuracy: 0.9695 - val_loss: 0.1338 - learning_rate: 0.0028\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0027135827864641087.\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 192ms/step - accuracy: 0.9673 - loss: 0.1349 - val_accuracy: 0.9691 - val_loss: 0.1343 - learning_rate: 0.0027\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.002640680826610367.\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 228ms/step - accuracy: 0.9670 - loss: 0.1336 - val_accuracy: 0.9681 - val_loss: 0.1346 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.002560748039745465.\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 188ms/step - accuracy: 0.9681 - loss: 0.1324 - val_accuracy: 0.9680 - val_loss: 0.1362 - learning_rate: 0.0026\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.002474277238080777.\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 229ms/step - accuracy: 0.9686 - loss: 0.1306 - val_accuracy: 0.9678 - val_loss: 0.1371 - learning_rate: 0.0025\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0023818015428630217.\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 191ms/step - accuracy: 0.9686 - loss: 0.1290 - val_accuracy: 0.9679 - val_loss: 0.1378 - learning_rate: 0.0024\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022838910975045085.\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 227ms/step - accuracy: 0.9699 - loss: 0.1272 - val_accuracy: 0.9681 - val_loss: 0.1400 - learning_rate: 0.0023\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0021811495524593984.\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 187ms/step - accuracy: 0.9708 - loss: 0.1252 - val_accuracy: 0.9675 - val_loss: 0.1406 - learning_rate: 0.0022\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0020742103435179254.\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96962\n",
            "32/32 - 9s - 272ms/step - accuracy: 0.9711 - loss: 0.1238 - val_accuracy: 0.9670 - val_loss: 0.1418 - learning_rate: 0.0021\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0019637327864641084.\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 187ms/step - accuracy: 0.9724 - loss: 0.1199 - val_accuracy: 0.9656 - val_loss: 0.1452 - learning_rate: 0.0020\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0018503980121747014.\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 229ms/step - accuracy: 0.9733 - loss: 0.1181 - val_accuracy: 0.9657 - val_loss: 0.1482 - learning_rate: 0.0019\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0017349047672208342.\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 186ms/step - accuracy: 0.9744 - loss: 0.1159 - val_accuracy: 0.9651 - val_loss: 0.1491 - learning_rate: 0.0017\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.001617965105863049.\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 224ms/step - accuracy: 0.9754 - loss: 0.1129 - val_accuracy: 0.9659 - val_loss: 0.1513 - learning_rate: 0.0016\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0015003.\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 187ms/step - accuracy: 0.9767 - loss: 0.1107 - val_accuracy: 0.9638 - val_loss: 0.1559 - learning_rate: 0.0015\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.001382634894136951.\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 225ms/step - accuracy: 0.9772 - loss: 0.1080 - val_accuracy: 0.9629 - val_loss: 0.1597 - learning_rate: 0.0014\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.001265695232779166.\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 186ms/step - accuracy: 0.9790 - loss: 0.1046 - val_accuracy: 0.9629 - val_loss: 0.1633 - learning_rate: 0.0013\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0011502019878252988.\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 226ms/step - accuracy: 0.9800 - loss: 0.1031 - val_accuracy: 0.9605 - val_loss: 0.1705 - learning_rate: 0.0012\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0010368672135358914.\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 186ms/step - accuracy: 0.9813 - loss: 0.1004 - val_accuracy: 0.9579 - val_loss: 0.1715 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0009263896564820749.\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 225ms/step - accuracy: 0.9830 - loss: 0.0971 - val_accuracy: 0.9605 - val_loss: 0.1734 - learning_rate: 9.2639e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0008194504475406018.\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 186ms/step - accuracy: 0.9844 - loss: 0.0940 - val_accuracy: 0.9601 - val_loss: 0.1773 - learning_rate: 8.1945e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0007167089024954917.\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 226ms/step - accuracy: 0.9853 - loss: 0.0908 - val_accuracy: 0.9611 - val_loss: 0.1788 - learning_rate: 7.1671e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0006187984571369782.\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 189ms/step - accuracy: 0.9877 - loss: 0.0875 - val_accuracy: 0.9605 - val_loss: 0.1829 - learning_rate: 6.1880e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0005263227619192238.\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 228ms/step - accuracy: 0.9881 - loss: 0.0862 - val_accuracy: 0.9597 - val_loss: 0.1846 - learning_rate: 5.2632e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0004398519602545348.\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 188ms/step - accuracy: 0.9887 - loss: 0.0842 - val_accuracy: 0.9589 - val_loss: 0.1856 - learning_rate: 4.3985e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00035991917338963365.\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 215ms/step - accuracy: 0.9894 - loss: 0.0830 - val_accuracy: 0.9592 - val_loss: 0.1887 - learning_rate: 3.5992e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.00028701721353589153.\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9898 - loss: 0.0819 - val_accuracy: 0.9585 - val_loss: 0.1923 - learning_rate: 2.8702e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.000221595545518168.\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 214ms/step - accuracy: 0.9904 - loss: 0.0802 - val_accuracy: 0.9597 - val_loss: 0.1921 - learning_rate: 2.2160e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.00016405751567470485.\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9906 - loss: 0.0803 - val_accuracy: 0.9595 - val_loss: 0.1923 - learning_rate: 1.6406e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.00011475786509282328.\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9911 - loss: 0.0796 - val_accuracy: 0.9594 - val_loss: 0.1936 - learning_rate: 1.1476e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 7.400054251215825e-05.\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9920 - loss: 0.0783 - val_accuracy: 0.9594 - val_loss: 0.1935 - learning_rate: 7.4001e-05\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 4.203683037960447e-05.\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9918 - loss: 0.0785 - val_accuracy: 0.9595 - val_loss: 0.1941 - learning_rate: 4.2037e-05\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 1.9063795609472052e-05.\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9915 - loss: 0.0786 - val_accuracy: 0.9595 - val_loss: 0.1942 - learning_rate: 1.9064e-05\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 5.223074600427993e-06.\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 213ms/step - accuracy: 0.9915 - loss: 0.0782 - val_accuracy: 0.9596 - val_loss: 0.1942 - learning_rate: 5.2231e-06\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9918 - loss: 0.0783 - val_accuracy: 0.9595 - val_loss: 0.1942 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 216ms/step - accuracy: 0.9917 - loss: 0.0779 - val_accuracy: 0.9596 - val_loss: 0.1942 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9913 - loss: 0.0783 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 205ms/step - accuracy: 0.9918 - loss: 0.0782 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 183ms/step - accuracy: 0.9916 - loss: 0.0783 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 208ms/step - accuracy: 0.9917 - loss: 0.0781 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.96962\n",
            "32/32 - 9s - 287ms/step - accuracy: 0.9915 - loss: 0.0786 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9920 - loss: 0.0779 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9920 - loss: 0.0781 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9919 - loss: 0.0775 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 200ms/step - accuracy: 0.9920 - loss: 0.0773 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 225ms/step - accuracy: 0.9915 - loss: 0.0787 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 175ms/step - accuracy: 0.9917 - loss: 0.0780 - val_accuracy: 0.9596 - val_loss: 0.1943 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 214ms/step - accuracy: 0.9917 - loss: 0.0781 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 175ms/step - accuracy: 0.9915 - loss: 0.0784 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 211ms/step - accuracy: 0.9921 - loss: 0.0783 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9919 - loss: 0.0782 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 213ms/step - accuracy: 0.9918 - loss: 0.0778 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 175ms/step - accuracy: 0.9921 - loss: 0.0781 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 211ms/step - accuracy: 0.9923 - loss: 0.0778 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 61: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 174ms/step - accuracy: 0.9920 - loss: 0.0777 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 229ms/step - accuracy: 0.9915 - loss: 0.0780 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9918 - loss: 0.0784 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9918 - loss: 0.0780 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 175ms/step - accuracy: 0.9922 - loss: 0.0772 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 210ms/step - accuracy: 0.9913 - loss: 0.0783 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 174ms/step - accuracy: 0.9915 - loss: 0.0782 - val_accuracy: 0.9596 - val_loss: 0.1944 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.96962\n",
            "32/32 - 11s - 342ms/step - accuracy: 0.9921 - loss: 0.0780 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9918 - loss: 0.0779 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.96962\n",
            "32/32 - 10s - 318ms/step - accuracy: 0.9916 - loss: 0.0783 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9923 - loss: 0.0775 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9918 - loss: 0.0784 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 210ms/step - accuracy: 0.9919 - loss: 0.0781 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.96962\n",
            "32/32 - 10s - 305ms/step - accuracy: 0.9918 - loss: 0.0777 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 189ms/step - accuracy: 0.9923 - loss: 0.0773 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 76/100\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 198ms/step - accuracy: 0.9921 - loss: 0.0778 - val_accuracy: 0.9596 - val_loss: 0.1945 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 77/100\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 190ms/step - accuracy: 0.9920 - loss: 0.0785 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 78/100\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 184ms/step - accuracy: 0.9917 - loss: 0.0779 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 79/100\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 199ms/step - accuracy: 0.9920 - loss: 0.0775 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 80/100\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9922 - loss: 0.0777 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 81/100\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.96962\n",
            "32/32 - 10s - 320ms/step - accuracy: 0.9920 - loss: 0.0778 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 82/100\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9914 - loss: 0.0790 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 83/100\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 178ms/step - accuracy: 0.9918 - loss: 0.0778 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 84/100\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 212ms/step - accuracy: 0.9918 - loss: 0.0781 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 85/100\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 176ms/step - accuracy: 0.9920 - loss: 0.0775 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 86/100\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.96962\n",
            "32/32 - 10s - 318ms/step - accuracy: 0.9917 - loss: 0.0783 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 87/100\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 210ms/step - accuracy: 0.9916 - loss: 0.0784 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 88/100\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 175ms/step - accuracy: 0.9924 - loss: 0.0775 - val_accuracy: 0.9595 - val_loss: 0.1946 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 89/100\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 198ms/step - accuracy: 0.9920 - loss: 0.0772 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 90/100\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 185ms/step - accuracy: 0.9912 - loss: 0.0787 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 91/100\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 199ms/step - accuracy: 0.9923 - loss: 0.0773 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 92/100\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.96962\n",
            "32/32 - 9s - 296ms/step - accuracy: 0.9921 - loss: 0.0775 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 93/100\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 213ms/step - accuracy: 0.9918 - loss: 0.0782 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 94/100\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.96962\n",
            "32/32 - 10s - 325ms/step - accuracy: 0.9923 - loss: 0.0772 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 95/100\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9918 - loss: 0.0780 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 96/100\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 209ms/step - accuracy: 0.9915 - loss: 0.0784 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 97/100\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 177ms/step - accuracy: 0.9917 - loss: 0.0773 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 98/100\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.96962\n",
            "32/32 - 6s - 200ms/step - accuracy: 0.9919 - loss: 0.0774 - val_accuracy: 0.9595 - val_loss: 0.1947 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 99/100\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.96962\n",
            "32/32 - 9s - 295ms/step - accuracy: 0.9919 - loss: 0.0778 - val_accuracy: 0.9595 - val_loss: 0.1948 - learning_rate: 6.0000e-07\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 6.000000000000001e-07.\n",
            "Epoch 100/100\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.96962\n",
            "32/32 - 7s - 210ms/step - accuracy: 0.9915 - loss: 0.0784 - val_accuracy: 0.9595 - val_loss: 0.1948 - learning_rate: 6.0000e-07\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
            "Test accuracy after 100 epochs → 0.953000\n",
            "Saved results JSON: /content/job/acc_results.json\n",
            "Saved accuracy plot: /content/job/accuracy_vs_epochs.png\n"
          ]
        }
      ],
      "source": [
        "!pip install -q xgboost\n",
        "\n",
        "import os, json, math, itertools, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "\n",
        "CSV_PATH = \"/content/final_ml_dataset_50000.csv\"\n",
        "TARGET = \"self_harm_flag\"\n",
        "VAL_SIZE = 0.20\n",
        "SEED = 42\n",
        "\n",
        "HIDDEN_SIZES = [512, 256, 128]\n",
        "DROPOUT_RATE = 0.10\n",
        "LABEL_SMOOTH = 0.02\n",
        "MAX_CROSS_PAIRS = 20\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "INITIAL_LR = 3e-3\n",
        "SAVE_DIR = \"/content/job\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "EPOCH_BUDGETS = [10, 50, 100]\n",
        "\n",
        "RESULTS_JSON = os.path.join(SAVE_DIR, \"acc_results.json\")\n",
        "ACCURACY_PNG = os.path.join(SAVE_DIR, \"accuracy_vs_epochs.png\")\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "print(\"Mixed precision enabled!\")\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Strategy replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "def is_id_like(n):\n",
        "    n = str(n).lower().strip()\n",
        "    return n == \"id\" or n.endswith(\"_id\") or n.startswith(\"id_\")\n",
        "\n",
        "def add_datetime_parts(df, target):\n",
        "    df = df.copy()\n",
        "    dtcols = []\n",
        "    for c in df.columns:\n",
        "        if c == target:\n",
        "            continue\n",
        "        if df[c].dtype == object:\n",
        "            try:\n",
        "                df[c] = pd.to_datetime(df[c], errors=\"raise\")\n",
        "                dtcols.append(c)\n",
        "            except:\n",
        "                pass\n",
        "        elif np.issubdtype(df[c].dtype, np.datetime64):\n",
        "            dtcols.append(c)\n",
        "    for c in dtcols:\n",
        "        df[c+\"_year\"]  = df[c].dt.year\n",
        "        df[c+\"_month\"] = df[c].dt.month\n",
        "        df[c+\"_day\"]   = df[c].dt.day\n",
        "        df[c+\"_hour\"]  = df[c].dt.hour\n",
        "        df[c+\"_dow\"]   = df[c].dt.dayofweek\n",
        "        df.drop(columns=[c], inplace=True)\n",
        "    return df\n",
        "\n",
        "def auto_feature_crosses(Xdf, max_pairs=20):\n",
        "    nums = Xdf.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if len(nums) < 2:\n",
        "        return Xdf, []\n",
        "    vari = Xdf[nums].var().sort_values(ascending=False)\n",
        "    tops = vari.index[:max_pairs+2]\n",
        "    pairs = list(itertools.combinations(tops, 2))[:max_pairs]\n",
        "    for a, b in pairs:\n",
        "        Xdf[f\"{a}*{b}\"] = Xdf[a]*Xdf[b]\n",
        "    return Xdf, pairs\n",
        "\n",
        "def se_block(x, ratio=8, name=\"se\"):\n",
        "    channels = int(x.shape[-1])\n",
        "    s = layers.Reshape((1, channels), name=f\"{name}_reshape_in\")(x)\n",
        "    s = layers.GlobalAveragePooling1D(name=f\"{name}_gap\")(s)\n",
        "    s = layers.Dense(max(1, channels // ratio), activation=\"relu\", name=f\"{name}_fc1\")(s)\n",
        "    s = layers.Dense(channels, activation=\"sigmoid\", name=f\"{name}_fc2\")(s)\n",
        "    s = layers.Reshape((channels,), name=f\"{name}_reshape_out\")(s)\n",
        "    return layers.Multiply(name=f\"{name}_scale\")([x, s])\n",
        "\n",
        "def make_cosine_lr_fn(initial_lr, decay_epochs=40, alpha=0.0002):\n",
        "    def lr_fn(epoch):\n",
        "        t = min(epoch, decay_epochs)\n",
        "        cos_val = 0.5 * (1 + math.cos(math.pi * t / decay_epochs))\n",
        "        lr = initial_lr * (alpha + (1 - alpha) * cos_val)\n",
        "        return lr\n",
        "    return lr_fn\n",
        "\n",
        "print(\"Loading:\", CSV_PATH)\n",
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "\n",
        "df = df.drop(columns=[c for c in df.columns if is_id_like(c)], errors=\"ignore\")\n",
        "\n",
        "nunique = df.nunique(dropna=False)\n",
        "df = df.drop(columns=nunique[nunique <= 1].index.tolist())\n",
        "\n",
        "df = add_datetime_parts(df, TARGET)\n",
        "\n",
        "if TARGET not in df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET}' not found\")\n",
        "\n",
        "y_raw = df[TARGET].values\n",
        "classes = np.unique(y_raw)\n",
        "class_map = {str(c): i for i, c in enumerate(classes)}\n",
        "y = np.array([class_map[str(v)] for v in y_raw], dtype=int)\n",
        "\n",
        "X = df.drop(columns=[TARGET]).copy()\n",
        "\n",
        "for c in X.columns:\n",
        "    if X[c].dtype == object:\n",
        "        _, inv = np.unique(X[c].astype(str), return_inverse=True)\n",
        "        X[c] = inv.astype(np.float32)\n",
        "\n",
        "X, used_pairs = auto_feature_crosses(X, MAX_CROSS_PAIRS)\n",
        "print(\"Feature crosses added:\", used_pairs)\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X.values, y, test_size=VAL_SIZE, random_state=SEED, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=VAL_SIZE, random_state=SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(np.float32))\n",
        "X_val   = scaler.transform(X_val.astype(np.float32))\n",
        "X_test  = scaler.transform(X_test.astype(np.float32))\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(classes)\n",
        "print(\"Input dim:\", input_dim, \"Num classes:\", num_classes)\n",
        "\n",
        "def build_widedeep():\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    wide_logits = layers.Dense(num_classes)(inputs)\n",
        "\n",
        "    x = inputs\n",
        "    for i, h in enumerate(HIDDEN_SIZES, 1):\n",
        "        x = layers.Dense(h, kernel_initializer=\"he_normal\")(x)\n",
        "        x = layers.Activation(\"gelu\")(x)\n",
        "        x = layers.Dropout(DROPOUT_RATE)(x)\n",
        "        x = se_block(x, ratio=8, name=f\"se_{i}\")\n",
        "\n",
        "    deep_logits = layers.Dense(num_classes)(x)\n",
        "    combined = layers.Add()([wide_logits, deep_logits])\n",
        "    out = layers.Activation(\"softmax\", dtype=\"float32\")(combined)\n",
        "    return keras.Model(inputs, out)\n",
        "\n",
        "results = {}\n",
        "for epochs in EPOCH_BUDGETS:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Training for {epochs} epochs...\")\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = build_widedeep()\n",
        "        opt = keras.optimizers.Adam(learning_rate=INITIAL_LR)\n",
        "        model.compile(\n",
        "            optimizer=opt,\n",
        "            loss=keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTH),\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "    y_train_oh = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_val_oh   = keras.utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    lr_schedule = make_cosine_lr_fn(INITIAL_LR)\n",
        "    cbs = [\n",
        "        callbacks.ModelCheckpoint(\n",
        "            os.path.join(SAVE_DIR, f\"model_{epochs}.keras\"),\n",
        "            save_best_only=True,\n",
        "            monitor=\"val_accuracy\",\n",
        "            mode=\"max\",\n",
        "            verbose=1,\n",
        "        ),\n",
        "        callbacks.LearningRateScheduler(lambda ep: lr_schedule(ep), verbose=1)\n",
        "    ]\n",
        "\n",
        "    hist = model.fit(\n",
        "        X_train, y_train_oh,\n",
        "        validation_data=(X_val, y_val_oh),\n",
        "        epochs=epochs,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=cbs,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    preds = model.predict(X_test).argmax(axis=1)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(f\"Test accuracy after {epochs} epochs → {acc:.6f}\")\n",
        "    results[epochs] = float(acc)\n",
        "\n",
        "with open(RESULTS_JSON, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "x = sorted(results.keys())\n",
        "y = [results[k] for k in x]\n",
        "plt.plot(x, y, marker=\"o\")\n",
        "for a, b in zip(x, y):\n",
        "    plt.text(a, b, f\"{b:.4f}\", ha=\"center\", va=\"bottom\")\n",
        "plt.title(\"SE + WideDeep Accuracy vs Epoch Budgets\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.savefig(ACCURACY_PNG, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved results JSON:\", RESULTS_JSON)\n",
        "print(\"Saved accuracy plot:\", ACCURACY_PNG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1kuSHSpzI4l",
        "outputId": "94d7f048-7b09-4634-af59-3ccb2986f355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using float32 policy (mixed precision disabled).\n",
            "\n",
            "============================================================\n",
            "Running ensemble for budget 100 epochs (each run may early stop)\n",
            "\n",
            "--- Training seed=42 ---\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95350, saving model to /content/job/best_seed_42.keras\n",
            "125/125 - 16s - 132ms/step - accuracy: 0.9376 - loss: 0.2081 - val_accuracy: 0.9535 - val_loss: 0.1795 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95350 to 0.96613, saving model to /content/job/best_seed_42.keras\n",
            "125/125 - 9s - 75ms/step - accuracy: 0.9624 - loss: 0.1264 - val_accuracy: 0.9661 - val_loss: 0.1150 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96613 to 0.96863, saving model to /content/job/best_seed_42.keras\n",
            "125/125 - 10s - 81ms/step - accuracy: 0.9625 - loss: 0.1221 - val_accuracy: 0.9686 - val_loss: 0.1087 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.96863\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9625 - loss: 0.1201 - val_accuracy: 0.9681 - val_loss: 0.1075 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.96863\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9633 - loss: 0.1186 - val_accuracy: 0.9680 - val_loss: 0.1069 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96863 to 0.96875, saving model to /content/job/best_seed_42.keras\n",
            "125/125 - 5s - 39ms/step - accuracy: 0.9643 - loss: 0.1162 - val_accuracy: 0.9688 - val_loss: 0.1074 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96875\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9637 - loss: 0.1147 - val_accuracy: 0.9688 - val_loss: 0.1071 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96875\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9647 - loss: 0.1133 - val_accuracy: 0.9681 - val_loss: 0.1076 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96875\n",
            "125/125 - 5s - 36ms/step - accuracy: 0.9647 - loss: 0.1112 - val_accuracy: 0.9676 - val_loss: 0.1078 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96875\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9650 - loss: 0.1100 - val_accuracy: 0.9681 - val_loss: 0.1081 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96875\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "125/125 - 5s - 41ms/step - accuracy: 0.9651 - loss: 0.1084 - val_accuracy: 0.9684 - val_loss: 0.1081 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96875\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9668 - loss: 0.1043 - val_accuracy: 0.9681 - val_loss: 0.1091 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96875\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9683 - loss: 0.1026 - val_accuracy: 0.9675 - val_loss: 0.1100 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96875\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9682 - loss: 0.1016 - val_accuracy: 0.9675 - val_loss: 0.1107 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96875\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9684 - loss: 0.0991 - val_accuracy: 0.9664 - val_loss: 0.1130 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96875\n",
            "125/125 - 4s - 34ms/step - accuracy: 0.9676 - loss: 0.0992 - val_accuracy: 0.9669 - val_loss: 0.1145 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96875\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9684 - loss: 0.0971 - val_accuracy: 0.9657 - val_loss: 0.1151 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96875\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9696 - loss: 0.0936 - val_accuracy: 0.9661 - val_loss: 0.1170 - learning_rate: 2.5000e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 140ms/step\n",
            "Seed 42 test accuracy: 0.964000\n",
            "\n",
            "--- Training seed=49 ---\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96050, saving model to /content/job/best_seed_49.keras\n",
            "125/125 - 7s - 54ms/step - accuracy: 0.9405 - loss: 0.1973 - val_accuracy: 0.9605 - val_loss: 0.1695 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96050 to 0.96688, saving model to /content/job/best_seed_49.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9628 - loss: 0.1231 - val_accuracy: 0.9669 - val_loss: 0.1185 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96688 to 0.96763, saving model to /content/job/best_seed_49.keras\n",
            "125/125 - 5s - 42ms/step - accuracy: 0.9646 - loss: 0.1203 - val_accuracy: 0.9676 - val_loss: 0.1112 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96763 to 0.96812, saving model to /content/job/best_seed_49.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9638 - loss: 0.1178 - val_accuracy: 0.9681 - val_loss: 0.1117 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96812 to 0.96887, saving model to /content/job/best_seed_49.keras\n",
            "125/125 - 7s - 53ms/step - accuracy: 0.9644 - loss: 0.1153 - val_accuracy: 0.9689 - val_loss: 0.1093 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9649 - loss: 0.1138 - val_accuracy: 0.9686 - val_loss: 0.1088 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9656 - loss: 0.1118 - val_accuracy: 0.9686 - val_loss: 0.1092 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9662 - loss: 0.1112 - val_accuracy: 0.9684 - val_loss: 0.1084 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9663 - loss: 0.1085 - val_accuracy: 0.9680 - val_loss: 0.1103 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9668 - loss: 0.1075 - val_accuracy: 0.9679 - val_loss: 0.1094 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9669 - loss: 0.1058 - val_accuracy: 0.9679 - val_loss: 0.1104 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96887\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9671 - loss: 0.1047 - val_accuracy: 0.9681 - val_loss: 0.1105 - learning_rate: 1.0000e-03\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_accuracy improved from 0.96887 to 0.96925, saving model to /content/job/best_seed_49.keras\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9670 - loss: 0.1031 - val_accuracy: 0.9693 - val_loss: 0.1116 - learning_rate: 1.0000e-03\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96925\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9673 - loss: 0.1016 - val_accuracy: 0.9675 - val_loss: 0.1134 - learning_rate: 1.0000e-03\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96925\n",
            "125/125 - 6s - 50ms/step - accuracy: 0.9689 - loss: 0.0963 - val_accuracy: 0.9671 - val_loss: 0.1156 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96925\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9694 - loss: 0.0950 - val_accuracy: 0.9671 - val_loss: 0.1176 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96925\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9693 - loss: 0.0938 - val_accuracy: 0.9666 - val_loss: 0.1201 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96925\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9696 - loss: 0.0918 - val_accuracy: 0.9666 - val_loss: 0.1223 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96925\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9704 - loss: 0.0905 - val_accuracy: 0.9666 - val_loss: 0.1229 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96925\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9708 - loss: 0.0888 - val_accuracy: 0.9664 - val_loss: 0.1253 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96925\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9726 - loss: 0.0845 - val_accuracy: 0.9655 - val_loss: 0.1296 - learning_rate: 2.5000e-04\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96925\n",
            "125/125 - 5s - 39ms/step - accuracy: 0.9734 - loss: 0.0815 - val_accuracy: 0.9643 - val_loss: 0.1327 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96925\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9738 - loss: 0.0802 - val_accuracy: 0.9645 - val_loss: 0.1395 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.96925\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9738 - loss: 0.0796 - val_accuracy: 0.9640 - val_loss: 0.1404 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.96925\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9746 - loss: 0.0787 - val_accuracy: 0.9650 - val_loss: 0.1416 - learning_rate: 2.5000e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n",
            "Seed 49 test accuracy: 0.961300\n",
            "\n",
            "--- Training seed=56 ---\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95125, saving model to /content/job/best_seed_56.keras\n",
            "125/125 - 6s - 50ms/step - accuracy: 0.9522 - loss: 0.1730 - val_accuracy: 0.9513 - val_loss: 0.1780 - learning_rate: 1.0000e-03\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95125 to 0.96375, saving model to /content/job/best_seed_56.keras\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9632 - loss: 0.1226 - val_accuracy: 0.9638 - val_loss: 0.1212 - learning_rate: 1.0000e-03\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96375 to 0.96475, saving model to /content/job/best_seed_56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9641 - loss: 0.1192 - val_accuracy: 0.9647 - val_loss: 0.1147 - learning_rate: 1.0000e-03\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96475 to 0.96588, saving model to /content/job/best_seed_56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9639 - loss: 0.1164 - val_accuracy: 0.9659 - val_loss: 0.1128 - learning_rate: 1.0000e-03\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96588 to 0.96688, saving model to /content/job/best_seed_56.keras\n",
            "125/125 - 6s - 44ms/step - accuracy: 0.9651 - loss: 0.1149 - val_accuracy: 0.9669 - val_loss: 0.1108 - learning_rate: 1.0000e-03\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96688 to 0.96700, saving model to /content/job/best_seed_56.keras\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9650 - loss: 0.1138 - val_accuracy: 0.9670 - val_loss: 0.1103 - learning_rate: 1.0000e-03\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9652 - loss: 0.1118 - val_accuracy: 0.9668 - val_loss: 0.1098 - learning_rate: 1.0000e-03\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96700\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9655 - loss: 0.1107 - val_accuracy: 0.9659 - val_loss: 0.1096 - learning_rate: 1.0000e-03\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9657 - loss: 0.1091 - val_accuracy: 0.9657 - val_loss: 0.1092 - learning_rate: 1.0000e-03\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9659 - loss: 0.1087 - val_accuracy: 0.9665 - val_loss: 0.1090 - learning_rate: 1.0000e-03\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 32ms/step - accuracy: 0.9666 - loss: 0.1064 - val_accuracy: 0.9668 - val_loss: 0.1093 - learning_rate: 1.0000e-03\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96700\n",
            "125/125 - 5s - 36ms/step - accuracy: 0.9668 - loss: 0.1046 - val_accuracy: 0.9664 - val_loss: 0.1094 - learning_rate: 1.0000e-03\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 32ms/step - accuracy: 0.9673 - loss: 0.1027 - val_accuracy: 0.9654 - val_loss: 0.1116 - learning_rate: 1.0000e-03\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9680 - loss: 0.1011 - val_accuracy: 0.9651 - val_loss: 0.1120 - learning_rate: 1.0000e-03\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96700\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9681 - loss: 0.0994 - val_accuracy: 0.9660 - val_loss: 0.1109 - learning_rate: 1.0000e-03\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96700\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9686 - loss: 0.0991 - val_accuracy: 0.9664 - val_loss: 0.1147 - learning_rate: 1.0000e-03\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9694 - loss: 0.0943 - val_accuracy: 0.9654 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9700 - loss: 0.0906 - val_accuracy: 0.9653 - val_loss: 0.1166 - learning_rate: 5.0000e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "Seed 56 test accuracy: 0.962400\n",
            "\n",
            "Ensembled test accuracy (avg of 3 runs): 0.963500\n",
            "Done. Results saved to /content/job\n"
          ]
        }
      ],
      "source": [
        "import os, json, random, math\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, regularizers\n",
        "\n",
        "LABEL_SMOOTH = 0.0\n",
        "BATCH_SIZE = 256\n",
        "INITIAL_LR = 1e-3\n",
        "L2_REG = 1e-5\n",
        "ENSEMBLE_RUNS = 3\n",
        "EARLY_STOPPING_PATIENCE = 12\n",
        "\n",
        "try:\n",
        "    from tensorflow.keras import mixed_precision\n",
        "    mixed_precision.set_global_policy(\"float32\")\n",
        "    print(\"Using float32 policy (mixed precision disabled).\")\n",
        "except Exception as e:\n",
        "    print(\"Could not change precision policy:\", e)\n",
        "\n",
        "def build_widedeep_with_bn(input_dim, num_classes, hidden_sizes, dropout_rate, l2_reg):\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    wide_logits = layers.Dense(num_classes, kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
        "    x = inputs\n",
        "    for i, h in enumerate(hidden_sizes, 1):\n",
        "        x = layers.Dense(h, kernel_initializer=\"he_normal\",\n",
        "                         kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"swish\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "        x = se_block(x, ratio=8, name=f\"se_{i}\")\n",
        "    deep_logits = layers.Dense(num_classes, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    combined = layers.Add()([wide_logits, deep_logits])\n",
        "    out = layers.Activation(\"softmax\", dtype=\"float32\")(combined)\n",
        "    model = keras.Model(inputs, out)\n",
        "    return model\n",
        "\n",
        "def train_one_run(seed, epochs):\n",
        "    print(f\"\\n--- Training seed={seed} ---\")\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = build_widedeep_with_bn(\n",
        "            input_dim=input_dim,\n",
        "            num_classes=num_classes,\n",
        "            hidden_sizes=HIDDEN_SIZES,\n",
        "            dropout_rate=DROPOUT_RATE,\n",
        "            l2_reg=L2_REG\n",
        "        )\n",
        "        opt = keras.optimizers.Adam(learning_rate=INITIAL_LR)\n",
        "        model.compile(\n",
        "            optimizer=opt,\n",
        "            loss=keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTH),\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "    ckpt_path = os.path.join(SAVE_DIR, f\"best_seed_{seed}.keras\")\n",
        "    cb_list = [\n",
        "        callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1),\n",
        "        callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=EARLY_STOPPING_PATIENCE, mode=\"max\", restore_best_weights=True, verbose=1),\n",
        "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, verbose=1, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    y_train_oh = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_val_oh   = keras.utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    hist = model.fit(\n",
        "        X_train, y_train_oh,\n",
        "        validation_data=(X_val, y_val_oh),\n",
        "        epochs=epochs,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=cb_list,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        model.load_weights(ckpt_path)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    preds_proba = model.predict(X_test, batch_size=1024)\n",
        "    preds = preds_proba.argmax(axis=1)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(f\"Seed {seed} test accuracy: {acc:.6f}\")\n",
        "    return preds_proba, acc\n",
        "\n",
        "final_results = {}\n",
        "epochs_to_run = max(EPOCH_BUDGETS)\n",
        "for epochs in [epochs_to_run]:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Running ensemble for budget {epochs} epochs (each run may early stop)\")\n",
        "    all_preds = []\n",
        "    accs = []\n",
        "    for r in range(ENSEMBLE_RUNS):\n",
        "        seed = SEED + r*7\n",
        "        preds_proba, acc = train_one_run(seed, epochs)\n",
        "        all_preds.append(preds_proba)\n",
        "        accs.append(acc)\n",
        "\n",
        "    avg_preds = np.mean(np.stack(all_preds, axis=0), axis=0)\n",
        "    final_preds = avg_preds.argmax(axis=1)\n",
        "    final_acc = accuracy_score(y_test, final_preds)\n",
        "    print(f\"\\nEnsembled test accuracy (avg of {ENSEMBLE_RUNS} runs): {final_acc:.6f}\")\n",
        "    final_results[epochs] = {\n",
        "        \"per_run_accs\": accs,\n",
        "        \"ensemble_acc\": float(final_acc),\n",
        "    }\n",
        "\n",
        "with open(os.path.join(SAVE_DIR, \"improved_results.json\"), \"w\") as f:\n",
        "    json.dump(final_results, f, indent=2)\n",
        "\n",
        "print(\"Done. Results saved to\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AimHs_5yzV6M",
        "outputId": "f8e90d69-c83c-4982-a7f5-942e30741d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF version: 2.19.0\n",
            "GPUs: []\n",
            "Using float32 policy (stable numerics).\n",
            "Strategy replicas: 1\n",
            "Loading: final_ml_dataset_50000.csv\n",
            "Loaded shape: (50000, 11)\n",
            "Added feature crosses: [('total_tweets_estimate', 'followers'), ('total_tweets_estimate', 'signup_date_day'), ('total_tweets_estimate', 'signup_date_month'), ('total_tweets_estimate', 'signup_date_year'), ('total_tweets_estimate', 'stress_keywords_freq_total'), ('total_tweets_estimate', 'signup_date_dow'), ('total_tweets_estimate', 'stress_keywords_freq_tweets'), ('total_tweets_estimate', 'past_month_activity'), ('total_tweets_estimate', 'avg_sentiment'), ('total_tweets_estimate', 'neg_tweet_ratio'), ('total_tweets_estimate', 'tweet_activity_ratio'), ('total_tweets_estimate', 'signup_date_hour'), ('followers', 'signup_date_day'), ('followers', 'signup_date_month'), ('followers', 'signup_date_year'), ('followers', 'stress_keywords_freq_total'), ('followers', 'signup_date_dow'), ('followers', 'stress_keywords_freq_tweets'), ('followers', 'past_month_activity'), ('followers', 'avg_sentiment')]\n",
            "Input dim: 33 Num classes: 2\n",
            "Train/Val/Test shapes: (32000, 33) (8000, 33) (10000, 33)\n",
            "\n",
            "================================================================================\n",
            "Running experiments for budget 15 epochs (early stopping may stop sooner)\n",
            "\n",
            "--- Training seed=42 (e15_r0) ---\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95350, saving model to /content/job/best_e15_r0_seed42.keras\n",
            "125/125 - 16s - 129ms/step - accuracy: 0.9376 - loss: 0.2081 - val_accuracy: 0.9535 - val_loss: 0.1795 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95350 to 0.96613, saving model to /content/job/best_e15_r0_seed42.keras\n",
            "125/125 - 9s - 71ms/step - accuracy: 0.9624 - loss: 0.1264 - val_accuracy: 0.9661 - val_loss: 0.1150 - learning_rate: 9.9846e-04\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96613 to 0.96850, saving model to /content/job/best_e15_r0_seed42.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9625 - loss: 0.1220 - val_accuracy: 0.9685 - val_loss: 0.1087 - learning_rate: 9.9385e-04\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.96850\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9625 - loss: 0.1200 - val_accuracy: 0.9684 - val_loss: 0.1074 - learning_rate: 9.8619e-04\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.96850\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9631 - loss: 0.1185 - val_accuracy: 0.9681 - val_loss: 0.1069 - learning_rate: 9.7553e-04\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96850 to 0.96863, saving model to /content/job/best_e15_r0_seed42.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9644 - loss: 0.1161 - val_accuracy: 0.9686 - val_loss: 0.1074 - learning_rate: 9.6195e-04\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96863\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9639 - loss: 0.1146 - val_accuracy: 0.9685 - val_loss: 0.1071 - learning_rate: 9.4551e-04\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96863\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9650 - loss: 0.1131 - val_accuracy: 0.9685 - val_loss: 0.1076 - learning_rate: 9.2633e-04\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96863\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9646 - loss: 0.1111 - val_accuracy: 0.9684 - val_loss: 0.1076 - learning_rate: 9.0453e-04\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96863\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9651 - loss: 0.1098 - val_accuracy: 0.9681 - val_loss: 0.1076 - learning_rate: 8.8023e-04\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96863 to 0.96887, saving model to /content/job/best_e15_r0_seed42.keras\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00042679134639911354.\n",
            "125/125 - 4s - 36ms/step - accuracy: 0.9654 - loss: 0.1081 - val_accuracy: 0.9689 - val_loss: 0.1080 - learning_rate: 4.2679e-04\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9660 - loss: 0.1063 - val_accuracy: 0.9676 - val_loss: 0.1092 - learning_rate: 8.2476e-04\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9677 - loss: 0.1048 - val_accuracy: 0.9676 - val_loss: 0.1106 - learning_rate: 7.9393e-04\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 32ms/step - accuracy: 0.9673 - loss: 0.1030 - val_accuracy: 0.9674 - val_loss: 0.1111 - learning_rate: 7.6130e-04\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96887\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9678 - loss: 0.1004 - val_accuracy: 0.9670 - val_loss: 0.1136 - learning_rate: 7.2705e-04\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n",
            "Seed 42 test accuracy: 0.962900\n",
            "\n",
            "--- Training seed=49 (e15_r1) ---\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96050, saving model to /content/job/best_e15_r1_seed49.keras\n",
            "125/125 - 7s - 60ms/step - accuracy: 0.9405 - loss: 0.1973 - val_accuracy: 0.9605 - val_loss: 0.1695 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96050 to 0.96650, saving model to /content/job/best_e15_r1_seed49.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9628 - loss: 0.1231 - val_accuracy: 0.9665 - val_loss: 0.1196 - learning_rate: 9.9846e-04\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96650 to 0.96775, saving model to /content/job/best_e15_r1_seed49.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9644 - loss: 0.1203 - val_accuracy: 0.9678 - val_loss: 0.1118 - learning_rate: 9.9385e-04\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96775 to 0.96788, saving model to /content/job/best_e15_r1_seed49.keras\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9636 - loss: 0.1178 - val_accuracy: 0.9679 - val_loss: 0.1117 - learning_rate: 9.8619e-04\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96788 to 0.96850, saving model to /content/job/best_e15_r1_seed49.keras\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9644 - loss: 0.1152 - val_accuracy: 0.9685 - val_loss: 0.1087 - learning_rate: 9.7553e-04\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96850 to 0.96900, saving model to /content/job/best_e15_r1_seed49.keras\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9650 - loss: 0.1137 - val_accuracy: 0.9690 - val_loss: 0.1086 - learning_rate: 9.6195e-04\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9656 - loss: 0.1117 - val_accuracy: 0.9686 - val_loss: 0.1096 - learning_rate: 9.4551e-04\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9663 - loss: 0.1112 - val_accuracy: 0.9676 - val_loss: 0.1084 - learning_rate: 9.2633e-04\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9667 - loss: 0.1082 - val_accuracy: 0.9678 - val_loss: 0.1098 - learning_rate: 9.0453e-04\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9670 - loss: 0.1072 - val_accuracy: 0.9680 - val_loss: 0.1100 - learning_rate: 8.8023e-04\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96900\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9675 - loss: 0.1053 - val_accuracy: 0.9678 - val_loss: 0.1109 - learning_rate: 8.5358e-04\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9674 - loss: 0.1043 - val_accuracy: 0.9682 - val_loss: 0.1109 - learning_rate: 8.2476e-04\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9676 - loss: 0.1025 - val_accuracy: 0.9688 - val_loss: 0.1122 - learning_rate: 7.9393e-04\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96900\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00038064850377850235.\n",
            "125/125 - 4s - 36ms/step - accuracy: 0.9681 - loss: 0.1010 - val_accuracy: 0.9680 - val_loss: 0.1137 - learning_rate: 3.8065e-04\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9681 - loss: 0.0986 - val_accuracy: 0.9675 - val_loss: 0.1146 - learning_rate: 7.2705e-04\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Seed 49 test accuracy: 0.962700\n",
            "\n",
            "--- Training seed=56 (e15_r2) ---\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95125, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 7s - 57ms/step - accuracy: 0.9522 - loss: 0.1730 - val_accuracy: 0.9513 - val_loss: 0.1780 - learning_rate: 1.0000e-03\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95125 to 0.96387, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 9s - 70ms/step - accuracy: 0.9632 - loss: 0.1226 - val_accuracy: 0.9639 - val_loss: 0.1211 - learning_rate: 9.9846e-04\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96387 to 0.96500, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9641 - loss: 0.1192 - val_accuracy: 0.9650 - val_loss: 0.1146 - learning_rate: 9.9385e-04\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96500 to 0.96637, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9640 - loss: 0.1163 - val_accuracy: 0.9664 - val_loss: 0.1127 - learning_rate: 9.8619e-04\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96637 to 0.96700, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9651 - loss: 0.1149 - val_accuracy: 0.9670 - val_loss: 0.1108 - learning_rate: 9.7553e-04\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 34ms/step - accuracy: 0.9648 - loss: 0.1137 - val_accuracy: 0.9670 - val_loss: 0.1102 - learning_rate: 9.6195e-04\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9652 - loss: 0.1116 - val_accuracy: 0.9668 - val_loss: 0.1095 - learning_rate: 9.4551e-04\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9657 - loss: 0.1105 - val_accuracy: 0.9663 - val_loss: 0.1094 - learning_rate: 9.2633e-04\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9658 - loss: 0.1087 - val_accuracy: 0.9657 - val_loss: 0.1090 - learning_rate: 9.0453e-04\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96700 to 0.96712, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9662 - loss: 0.1082 - val_accuracy: 0.9671 - val_loss: 0.1089 - learning_rate: 8.8023e-04\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96712 to 0.96737, saving model to /content/job/best_e15_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9665 - loss: 0.1058 - val_accuracy: 0.9674 - val_loss: 0.1092 - learning_rate: 8.5358e-04\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9668 - loss: 0.1039 - val_accuracy: 0.9666 - val_loss: 0.1092 - learning_rate: 8.2476e-04\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96737\n",
            "125/125 - 5s - 42ms/step - accuracy: 0.9681 - loss: 0.1020 - val_accuracy: 0.9653 - val_loss: 0.1116 - learning_rate: 7.9393e-04\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9680 - loss: 0.1004 - val_accuracy: 0.9650 - val_loss: 0.1119 - learning_rate: 7.6130e-04\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9683 - loss: 0.0983 - val_accuracy: 0.9664 - val_loss: 0.1114 - learning_rate: 7.2705e-04\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "Seed 56 test accuracy: 0.963900\n",
            "Ensemble (n=3) test accuracy: 0.964100\n",
            "\n",
            "================================================================================\n",
            "Running experiments for budget 150 epochs (early stopping may stop sooner)\n",
            "\n",
            "--- Training seed=42 (e150_r0) ---\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95350, saving model to /content/job/best_e150_r0_seed42.keras\n",
            "125/125 - 7s - 58ms/step - accuracy: 0.9376 - loss: 0.2081 - val_accuracy: 0.9535 - val_loss: 0.1795 - learning_rate: 1.0000e-03\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95350 to 0.96613, saving model to /content/job/best_e150_r0_seed42.keras\n",
            "125/125 - 5s - 40ms/step - accuracy: 0.9624 - loss: 0.1264 - val_accuracy: 0.9661 - val_loss: 0.1150 - learning_rate: 9.9846e-04\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96613 to 0.96850, saving model to /content/job/best_e150_r0_seed42.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9625 - loss: 0.1220 - val_accuracy: 0.9685 - val_loss: 0.1087 - learning_rate: 9.9385e-04\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.96850\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9625 - loss: 0.1200 - val_accuracy: 0.9684 - val_loss: 0.1074 - learning_rate: 9.8619e-04\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.96850\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9631 - loss: 0.1185 - val_accuracy: 0.9681 - val_loss: 0.1069 - learning_rate: 9.7553e-04\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96850 to 0.96863, saving model to /content/job/best_e150_r0_seed42.keras\n",
            "125/125 - 4s - 32ms/step - accuracy: 0.9644 - loss: 0.1161 - val_accuracy: 0.9686 - val_loss: 0.1074 - learning_rate: 9.6195e-04\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96863\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9639 - loss: 0.1146 - val_accuracy: 0.9685 - val_loss: 0.1071 - learning_rate: 9.4551e-04\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96863\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9650 - loss: 0.1131 - val_accuracy: 0.9685 - val_loss: 0.1076 - learning_rate: 9.2633e-04\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96863\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9646 - loss: 0.1111 - val_accuracy: 0.9684 - val_loss: 0.1076 - learning_rate: 9.0453e-04\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96863\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9651 - loss: 0.1098 - val_accuracy: 0.9681 - val_loss: 0.1076 - learning_rate: 8.8023e-04\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96863 to 0.96887, saving model to /content/job/best_e150_r0_seed42.keras\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00042679134639911354.\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9654 - loss: 0.1081 - val_accuracy: 0.9689 - val_loss: 0.1080 - learning_rate: 4.2679e-04\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96887\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9660 - loss: 0.1063 - val_accuracy: 0.9676 - val_loss: 0.1092 - learning_rate: 8.2476e-04\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9677 - loss: 0.1048 - val_accuracy: 0.9676 - val_loss: 0.1106 - learning_rate: 7.9393e-04\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9673 - loss: 0.1030 - val_accuracy: 0.9674 - val_loss: 0.1111 - learning_rate: 7.6130e-04\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9678 - loss: 0.1004 - val_accuracy: 0.9670 - val_loss: 0.1136 - learning_rate: 7.2705e-04\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9671 - loss: 0.1000 - val_accuracy: 0.9666 - val_loss: 0.1150 - learning_rate: 6.9140e-04\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96887\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0003272887843195349.\n",
            "125/125 - 4s - 34ms/step - accuracy: 0.9682 - loss: 0.0970 - val_accuracy: 0.9660 - val_loss: 0.1156 - learning_rate: 3.2729e-04\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96887\n",
            "125/125 - 5s - 36ms/step - accuracy: 0.9682 - loss: 0.0952 - val_accuracy: 0.9661 - val_loss: 0.1188 - learning_rate: 6.1680e-04\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9702 - loss: 0.0925 - val_accuracy: 0.9651 - val_loss: 0.1212 - learning_rate: 5.7830e-04\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9699 - loss: 0.0911 - val_accuracy: 0.9641 - val_loss: 0.1236 - learning_rate: 5.3932e-04\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96887\n",
            "125/125 - 5s - 40ms/step - accuracy: 0.9709 - loss: 0.0884 - val_accuracy: 0.9659 - val_loss: 0.1284 - learning_rate: 5.0010e-04\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9721 - loss: 0.0862 - val_accuracy: 0.9643 - val_loss: 0.1285 - learning_rate: 4.6088e-04\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96887\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00021094920521136373.\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9730 - loss: 0.0832 - val_accuracy: 0.9650 - val_loss: 0.1344 - learning_rate: 2.1095e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
            "Seed 42 test accuracy: 0.962900\n",
            "\n",
            "--- Training seed=49 (e150_r1) ---\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96050, saving model to /content/job/best_e150_r1_seed49.keras\n",
            "125/125 - 6s - 50ms/step - accuracy: 0.9405 - loss: 0.1973 - val_accuracy: 0.9605 - val_loss: 0.1695 - learning_rate: 1.0000e-03\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96050 to 0.96650, saving model to /content/job/best_e150_r1_seed49.keras\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9628 - loss: 0.1231 - val_accuracy: 0.9665 - val_loss: 0.1196 - learning_rate: 9.9846e-04\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96650 to 0.96775, saving model to /content/job/best_e150_r1_seed49.keras\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9644 - loss: 0.1203 - val_accuracy: 0.9678 - val_loss: 0.1118 - learning_rate: 9.9385e-04\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96775 to 0.96788, saving model to /content/job/best_e150_r1_seed49.keras\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9636 - loss: 0.1178 - val_accuracy: 0.9679 - val_loss: 0.1117 - learning_rate: 9.8619e-04\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96788 to 0.96850, saving model to /content/job/best_e150_r1_seed49.keras\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9644 - loss: 0.1152 - val_accuracy: 0.9685 - val_loss: 0.1087 - learning_rate: 9.7553e-04\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96850 to 0.96900, saving model to /content/job/best_e150_r1_seed49.keras\n",
            "125/125 - 4s - 34ms/step - accuracy: 0.9650 - loss: 0.1137 - val_accuracy: 0.9690 - val_loss: 0.1086 - learning_rate: 9.6195e-04\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9656 - loss: 0.1117 - val_accuracy: 0.9686 - val_loss: 0.1096 - learning_rate: 9.4551e-04\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9663 - loss: 0.1112 - val_accuracy: 0.9676 - val_loss: 0.1084 - learning_rate: 9.2633e-04\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96900\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9667 - loss: 0.1082 - val_accuracy: 0.9678 - val_loss: 0.1098 - learning_rate: 9.0453e-04\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9670 - loss: 0.1072 - val_accuracy: 0.9680 - val_loss: 0.1100 - learning_rate: 8.8023e-04\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9675 - loss: 0.1053 - val_accuracy: 0.9678 - val_loss: 0.1109 - learning_rate: 8.5358e-04\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96900\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9674 - loss: 0.1043 - val_accuracy: 0.9682 - val_loss: 0.1109 - learning_rate: 8.2476e-04\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9676 - loss: 0.1025 - val_accuracy: 0.9688 - val_loss: 0.1122 - learning_rate: 7.9393e-04\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96900\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00038064850377850235.\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9681 - loss: 0.1010 - val_accuracy: 0.9680 - val_loss: 0.1137 - learning_rate: 3.8065e-04\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96900\n",
            "125/125 - 6s - 51ms/step - accuracy: 0.9681 - loss: 0.0986 - val_accuracy: 0.9675 - val_loss: 0.1146 - learning_rate: 7.2705e-04\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9688 - loss: 0.0974 - val_accuracy: 0.9672 - val_loss: 0.1159 - learning_rate: 6.9140e-04\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9682 - loss: 0.0962 - val_accuracy: 0.9670 - val_loss: 0.1187 - learning_rate: 6.5458e-04\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9693 - loss: 0.0933 - val_accuracy: 0.9664 - val_loss: 0.1211 - learning_rate: 6.1680e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step\n",
            "Seed 49 test accuracy: 0.962700\n",
            "\n",
            "--- Training seed=56 (e150_r2) ---\n",
            "Epoch 1/150\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95125, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 6s - 49ms/step - accuracy: 0.9522 - loss: 0.1730 - val_accuracy: 0.9513 - val_loss: 0.1780 - learning_rate: 1.0000e-03\n",
            "Epoch 2/150\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95125 to 0.96387, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9632 - loss: 0.1226 - val_accuracy: 0.9639 - val_loss: 0.1211 - learning_rate: 9.9846e-04\n",
            "Epoch 3/150\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96387 to 0.96500, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9641 - loss: 0.1192 - val_accuracy: 0.9650 - val_loss: 0.1146 - learning_rate: 9.9385e-04\n",
            "Epoch 4/150\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96500 to 0.96637, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 4s - 34ms/step - accuracy: 0.9640 - loss: 0.1163 - val_accuracy: 0.9664 - val_loss: 0.1127 - learning_rate: 9.8619e-04\n",
            "Epoch 5/150\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96637 to 0.96700, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9651 - loss: 0.1149 - val_accuracy: 0.9670 - val_loss: 0.1108 - learning_rate: 9.7553e-04\n",
            "Epoch 6/150\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96700\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9648 - loss: 0.1137 - val_accuracy: 0.9670 - val_loss: 0.1102 - learning_rate: 9.6195e-04\n",
            "Epoch 7/150\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9652 - loss: 0.1116 - val_accuracy: 0.9668 - val_loss: 0.1095 - learning_rate: 9.4551e-04\n",
            "Epoch 8/150\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9657 - loss: 0.1105 - val_accuracy: 0.9663 - val_loss: 0.1094 - learning_rate: 9.2633e-04\n",
            "Epoch 9/150\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96700\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9658 - loss: 0.1087 - val_accuracy: 0.9657 - val_loss: 0.1090 - learning_rate: 9.0453e-04\n",
            "Epoch 10/150\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96700 to 0.96712, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9662 - loss: 0.1082 - val_accuracy: 0.9671 - val_loss: 0.1089 - learning_rate: 8.8023e-04\n",
            "Epoch 11/150\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96712 to 0.96737, saving model to /content/job/best_e150_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9665 - loss: 0.1058 - val_accuracy: 0.9674 - val_loss: 0.1092 - learning_rate: 8.5358e-04\n",
            "Epoch 12/150\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9668 - loss: 0.1039 - val_accuracy: 0.9666 - val_loss: 0.1092 - learning_rate: 8.2476e-04\n",
            "Epoch 13/150\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9681 - loss: 0.1020 - val_accuracy: 0.9653 - val_loss: 0.1116 - learning_rate: 7.9393e-04\n",
            "Epoch 14/150\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9680 - loss: 0.1004 - val_accuracy: 0.9650 - val_loss: 0.1119 - learning_rate: 7.6130e-04\n",
            "Epoch 15/150\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9683 - loss: 0.0983 - val_accuracy: 0.9664 - val_loss: 0.1114 - learning_rate: 7.2705e-04\n",
            "Epoch 16/150\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96737\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00034570173011161387.\n",
            "125/125 - 5s - 40ms/step - accuracy: 0.9688 - loss: 0.0977 - val_accuracy: 0.9657 - val_loss: 0.1141 - learning_rate: 3.4570e-04\n",
            "Epoch 17/150\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9698 - loss: 0.0954 - val_accuracy: 0.9647 - val_loss: 0.1149 - learning_rate: 6.5458e-04\n",
            "Epoch 18/150\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9698 - loss: 0.0924 - val_accuracy: 0.9656 - val_loss: 0.1169 - learning_rate: 6.1680e-04\n",
            "Epoch 19/150\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96737\n",
            "125/125 - 5s - 41ms/step - accuracy: 0.9707 - loss: 0.0899 - val_accuracy: 0.9659 - val_loss: 0.1178 - learning_rate: 5.7830e-04\n",
            "Epoch 20/150\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9713 - loss: 0.0885 - val_accuracy: 0.9649 - val_loss: 0.1210 - learning_rate: 5.3932e-04\n",
            "Epoch 21/150\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9717 - loss: 0.0864 - val_accuracy: 0.9644 - val_loss: 0.1225 - learning_rate: 5.0010e-04\n",
            "Epoch 22/150\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96737\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00023043915280140936.\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9722 - loss: 0.0840 - val_accuracy: 0.9651 - val_loss: 0.1245 - learning_rate: 2.3044e-04\n",
            "Epoch 23/150\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9740 - loss: 0.0808 - val_accuracy: 0.9649 - val_loss: 0.1262 - learning_rate: 4.2190e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Seed 56 test accuracy: 0.963900\n",
            "Ensemble (n=3) test accuracy: 0.964100\n",
            "\n",
            "================================================================================\n",
            "Running experiments for budget 300 epochs (early stopping may stop sooner)\n",
            "\n",
            "--- Training seed=42 (e300_r0) ---\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95350, saving model to /content/job/best_e300_r0_seed42.keras\n",
            "125/125 - 8s - 61ms/step - accuracy: 0.9376 - loss: 0.2081 - val_accuracy: 0.9535 - val_loss: 0.1795 - learning_rate: 1.0000e-03\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95350 to 0.96613, saving model to /content/job/best_e300_r0_seed42.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9624 - loss: 0.1264 - val_accuracy: 0.9661 - val_loss: 0.1150 - learning_rate: 9.9846e-04\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96613 to 0.96850, saving model to /content/job/best_e300_r0_seed42.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9625 - loss: 0.1220 - val_accuracy: 0.9685 - val_loss: 0.1087 - learning_rate: 9.9385e-04\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.96850\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9625 - loss: 0.1200 - val_accuracy: 0.9684 - val_loss: 0.1074 - learning_rate: 9.8619e-04\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.96850\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9631 - loss: 0.1185 - val_accuracy: 0.9681 - val_loss: 0.1069 - learning_rate: 9.7553e-04\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96850 to 0.96863, saving model to /content/job/best_e300_r0_seed42.keras\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9644 - loss: 0.1161 - val_accuracy: 0.9686 - val_loss: 0.1074 - learning_rate: 9.6195e-04\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96863\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9639 - loss: 0.1146 - val_accuracy: 0.9685 - val_loss: 0.1071 - learning_rate: 9.4551e-04\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96863\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9650 - loss: 0.1131 - val_accuracy: 0.9685 - val_loss: 0.1076 - learning_rate: 9.2633e-04\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96863\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9646 - loss: 0.1111 - val_accuracy: 0.9684 - val_loss: 0.1076 - learning_rate: 9.0453e-04\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96863\n",
            "125/125 - 5s - 36ms/step - accuracy: 0.9651 - loss: 0.1098 - val_accuracy: 0.9681 - val_loss: 0.1076 - learning_rate: 8.8023e-04\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96863 to 0.96887, saving model to /content/job/best_e300_r0_seed42.keras\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00042679134639911354.\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9654 - loss: 0.1081 - val_accuracy: 0.9689 - val_loss: 0.1080 - learning_rate: 4.2679e-04\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9660 - loss: 0.1063 - val_accuracy: 0.9676 - val_loss: 0.1092 - learning_rate: 8.2476e-04\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9677 - loss: 0.1048 - val_accuracy: 0.9676 - val_loss: 0.1106 - learning_rate: 7.9393e-04\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 34ms/step - accuracy: 0.9673 - loss: 0.1030 - val_accuracy: 0.9674 - val_loss: 0.1111 - learning_rate: 7.6130e-04\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9678 - loss: 0.1004 - val_accuracy: 0.9670 - val_loss: 0.1136 - learning_rate: 7.2705e-04\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9671 - loss: 0.1000 - val_accuracy: 0.9666 - val_loss: 0.1150 - learning_rate: 6.9140e-04\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96887\n",
            "\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0003272887843195349.\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9682 - loss: 0.0970 - val_accuracy: 0.9660 - val_loss: 0.1156 - learning_rate: 3.2729e-04\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9682 - loss: 0.0952 - val_accuracy: 0.9661 - val_loss: 0.1188 - learning_rate: 6.1680e-04\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9702 - loss: 0.0925 - val_accuracy: 0.9651 - val_loss: 0.1212 - learning_rate: 5.7830e-04\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 33ms/step - accuracy: 0.9699 - loss: 0.0911 - val_accuracy: 0.9641 - val_loss: 0.1236 - learning_rate: 5.3932e-04\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96887\n",
            "125/125 - 4s - 31ms/step - accuracy: 0.9709 - loss: 0.0884 - val_accuracy: 0.9659 - val_loss: 0.1284 - learning_rate: 5.0010e-04\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96887\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9721 - loss: 0.0862 - val_accuracy: 0.9643 - val_loss: 0.1285 - learning_rate: 4.6088e-04\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96887\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.00021094920521136373.\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9730 - loss: 0.0832 - val_accuracy: 0.9650 - val_loss: 0.1344 - learning_rate: 2.1095e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step\n",
            "Seed 42 test accuracy: 0.962900\n",
            "\n",
            "--- Training seed=49 (e300_r1) ---\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.96050, saving model to /content/job/best_e300_r1_seed49.keras\n",
            "125/125 - 6s - 52ms/step - accuracy: 0.9405 - loss: 0.1973 - val_accuracy: 0.9605 - val_loss: 0.1695 - learning_rate: 1.0000e-03\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.96050 to 0.96650, saving model to /content/job/best_e300_r1_seed49.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9628 - loss: 0.1231 - val_accuracy: 0.9665 - val_loss: 0.1196 - learning_rate: 9.9846e-04\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96650 to 0.96775, saving model to /content/job/best_e300_r1_seed49.keras\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9644 - loss: 0.1203 - val_accuracy: 0.9678 - val_loss: 0.1118 - learning_rate: 9.9385e-04\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96775 to 0.96788, saving model to /content/job/best_e300_r1_seed49.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9636 - loss: 0.1178 - val_accuracy: 0.9679 - val_loss: 0.1117 - learning_rate: 9.8619e-04\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96788 to 0.96850, saving model to /content/job/best_e300_r1_seed49.keras\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9644 - loss: 0.1152 - val_accuracy: 0.9685 - val_loss: 0.1087 - learning_rate: 9.7553e-04\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.96850 to 0.96900, saving model to /content/job/best_e300_r1_seed49.keras\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9650 - loss: 0.1137 - val_accuracy: 0.9690 - val_loss: 0.1086 - learning_rate: 9.6195e-04\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9656 - loss: 0.1117 - val_accuracy: 0.9686 - val_loss: 0.1096 - learning_rate: 9.4551e-04\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9663 - loss: 0.1112 - val_accuracy: 0.9676 - val_loss: 0.1084 - learning_rate: 9.2633e-04\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 30ms/step - accuracy: 0.9667 - loss: 0.1082 - val_accuracy: 0.9678 - val_loss: 0.1098 - learning_rate: 9.0453e-04\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9670 - loss: 0.1072 - val_accuracy: 0.9680 - val_loss: 0.1100 - learning_rate: 8.8023e-04\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9675 - loss: 0.1053 - val_accuracy: 0.9678 - val_loss: 0.1109 - learning_rate: 8.5358e-04\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9674 - loss: 0.1043 - val_accuracy: 0.9682 - val_loss: 0.1109 - learning_rate: 8.2476e-04\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96900\n",
            "125/125 - 6s - 47ms/step - accuracy: 0.9676 - loss: 0.1025 - val_accuracy: 0.9688 - val_loss: 0.1122 - learning_rate: 7.9393e-04\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96900\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00038064850377850235.\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9681 - loss: 0.1010 - val_accuracy: 0.9680 - val_loss: 0.1137 - learning_rate: 3.8065e-04\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9681 - loss: 0.0986 - val_accuracy: 0.9675 - val_loss: 0.1146 - learning_rate: 7.2705e-04\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96900\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9688 - loss: 0.0974 - val_accuracy: 0.9672 - val_loss: 0.1159 - learning_rate: 6.9140e-04\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96900\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9682 - loss: 0.0962 - val_accuracy: 0.9670 - val_loss: 0.1187 - learning_rate: 6.5458e-04\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96900\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9693 - loss: 0.0933 - val_accuracy: 0.9664 - val_loss: 0.1211 - learning_rate: 6.1680e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 6.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step\n",
            "Seed 49 test accuracy: 0.962700\n",
            "\n",
            "--- Training seed=56 (e300_r2) ---\n",
            "Epoch 1/300\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.95125, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 7s - 56ms/step - accuracy: 0.9522 - loss: 0.1730 - val_accuracy: 0.9513 - val_loss: 0.1780 - learning_rate: 1.0000e-03\n",
            "Epoch 2/300\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.95125 to 0.96387, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9632 - loss: 0.1226 - val_accuracy: 0.9639 - val_loss: 0.1211 - learning_rate: 9.9846e-04\n",
            "Epoch 3/300\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.96387 to 0.96500, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 5s - 39ms/step - accuracy: 0.9641 - loss: 0.1192 - val_accuracy: 0.9650 - val_loss: 0.1146 - learning_rate: 9.9385e-04\n",
            "Epoch 4/300\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.96500 to 0.96637, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9640 - loss: 0.1163 - val_accuracy: 0.9664 - val_loss: 0.1127 - learning_rate: 9.8619e-04\n",
            "Epoch 5/300\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.96637 to 0.96700, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9651 - loss: 0.1149 - val_accuracy: 0.9670 - val_loss: 0.1108 - learning_rate: 9.7553e-04\n",
            "Epoch 6/300\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.96700\n",
            "125/125 - 5s - 36ms/step - accuracy: 0.9648 - loss: 0.1137 - val_accuracy: 0.9670 - val_loss: 0.1102 - learning_rate: 9.6195e-04\n",
            "Epoch 7/300\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9652 - loss: 0.1116 - val_accuracy: 0.9668 - val_loss: 0.1095 - learning_rate: 9.4551e-04\n",
            "Epoch 8/300\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.96700\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9657 - loss: 0.1105 - val_accuracy: 0.9663 - val_loss: 0.1094 - learning_rate: 9.2633e-04\n",
            "Epoch 9/300\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.96700\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9658 - loss: 0.1087 - val_accuracy: 0.9657 - val_loss: 0.1090 - learning_rate: 9.0453e-04\n",
            "Epoch 10/300\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.96700 to 0.96712, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 5s - 37ms/step - accuracy: 0.9662 - loss: 0.1082 - val_accuracy: 0.9671 - val_loss: 0.1089 - learning_rate: 8.8023e-04\n",
            "Epoch 11/300\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.96712 to 0.96737, saving model to /content/job/best_e300_r2_seed56.keras\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9665 - loss: 0.1058 - val_accuracy: 0.9674 - val_loss: 0.1092 - learning_rate: 8.5358e-04\n",
            "Epoch 12/300\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9668 - loss: 0.1039 - val_accuracy: 0.9666 - val_loss: 0.1092 - learning_rate: 8.2476e-04\n",
            "Epoch 13/300\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.96737\n",
            "125/125 - 5s - 38ms/step - accuracy: 0.9681 - loss: 0.1020 - val_accuracy: 0.9653 - val_loss: 0.1116 - learning_rate: 7.9393e-04\n",
            "Epoch 14/300\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9680 - loss: 0.1004 - val_accuracy: 0.9650 - val_loss: 0.1119 - learning_rate: 7.6130e-04\n",
            "Epoch 15/300\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9683 - loss: 0.0983 - val_accuracy: 0.9664 - val_loss: 0.1114 - learning_rate: 7.2705e-04\n",
            "Epoch 16/300\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.96737\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00034570173011161387.\n",
            "125/125 - 4s - 35ms/step - accuracy: 0.9688 - loss: 0.0977 - val_accuracy: 0.9657 - val_loss: 0.1141 - learning_rate: 3.4570e-04\n",
            "Epoch 17/300\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 29ms/step - accuracy: 0.9698 - loss: 0.0954 - val_accuracy: 0.9647 - val_loss: 0.1149 - learning_rate: 6.5458e-04\n",
            "Epoch 18/300\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 27ms/step - accuracy: 0.9698 - loss: 0.0924 - val_accuracy: 0.9656 - val_loss: 0.1169 - learning_rate: 6.1680e-04\n",
            "Epoch 19/300\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9707 - loss: 0.0899 - val_accuracy: 0.9659 - val_loss: 0.1178 - learning_rate: 5.7830e-04\n",
            "Epoch 20/300\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.96737\n",
            "125/125 - 6s - 52ms/step - accuracy: 0.9713 - loss: 0.0885 - val_accuracy: 0.9649 - val_loss: 0.1210 - learning_rate: 5.3932e-04\n",
            "Epoch 21/300\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.96737\n",
            "125/125 - 3s - 28ms/step - accuracy: 0.9717 - loss: 0.0864 - val_accuracy: 0.9644 - val_loss: 0.1225 - learning_rate: 5.0010e-04\n",
            "Epoch 22/300\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.96737\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00023043915280140936.\n",
            "125/125 - 4s - 36ms/step - accuracy: 0.9722 - loss: 0.0840 - val_accuracy: 0.9651 - val_loss: 0.1245 - learning_rate: 2.3044e-04\n",
            "Epoch 23/300\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.96737\n",
            "125/125 - 4s - 28ms/step - accuracy: 0.9740 - loss: 0.0808 - val_accuracy: 0.9649 - val_loss: 0.1262 - learning_rate: 4.2190e-04\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Seed 56 test accuracy: 0.963900\n",
            "Ensemble (n=3) test accuracy: 0.964100\n",
            "Saved results JSON: /content/job/acc_results.json\n",
            "Saved accuracy plot: /content/job/accuracy_vs_epochs.png\n",
            "Finished. Results saved at: /content/job\n"
          ]
        }
      ],
      "source": [
        "!pip install -q xgboost\n",
        "\n",
        "import os, json, math, itertools, random, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, regularizers\n",
        "\n",
        "CSV_PATH = \"final_ml_dataset_50000.csv\"\n",
        "TARGET = \"self_harm_flag\"\n",
        "VAL_SIZE = 0.20\n",
        "SEED = 42\n",
        "\n",
        "HIDDEN_SIZES = [512, 256, 128]\n",
        "DROPOUT_RATE = 0.10\n",
        "\n",
        "LABEL_SMOOTH = 0.0\n",
        "BATCH_SIZE = 256\n",
        "INITIAL_LR = 1e-3\n",
        "L2_REG = 1e-5\n",
        "ENSEMBLE_RUNS = 3\n",
        "EARLY_STOPPING_PATIENCE = 12\n",
        "USE_MIXED_PRECISION = False\n",
        "EPOCH_BUDGETS = [15, 150, 300]\n",
        "\n",
        "SAVE_DIR = \"/content/job\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "RESULTS_JSON = os.path.join(SAVE_DIR, \"acc_results.json\")\n",
        "ACCURACY_PNG = os.path.join(SAVE_DIR, \"accuracy_vs_epochs.png\")\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "from tensorflow.keras import mixed_precision\n",
        "if USE_MIXED_PRECISION:\n",
        "    try:\n",
        "        mixed_precision.set_global_policy(\"mixed_float16\")\n",
        "        print(\"Mixed precision enabled.\")\n",
        "    except Exception as e:\n",
        "        print(\"Could not enable mixed precision:\", e)\n",
        "else:\n",
        "    try:\n",
        "        mixed_precision.set_global_policy(\"float32\")\n",
        "        print(\"Using float32 policy (stable numerics).\")\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Strategy replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "def is_id_like(n):\n",
        "    n = str(n).lower().strip()\n",
        "    return n == \"id\" or n.endswith(\"_id\") or n.startswith(\"id_\")\n",
        "\n",
        "def add_datetime_parts(df, target):\n",
        "    df = df.copy()\n",
        "    dtcols = []\n",
        "    for c in df.columns:\n",
        "        if c == target: continue\n",
        "        if df[c].dtype == object:\n",
        "            try:\n",
        "                df[c] = pd.to_datetime(df[c], errors=\"raise\")\n",
        "                dtcols.append(c)\n",
        "            except:\n",
        "                pass\n",
        "        elif np.issubdtype(df[c].dtype, np.datetime64):\n",
        "            dtcols.append(c)\n",
        "    for c in dtcols:\n",
        "        df[c+\"_year\"]  = df[c].dt.year\n",
        "        df[c+\"_month\"] = df[c].dt.month\n",
        "        df[c+\"_day\"]   = df[c].dt.day\n",
        "        df[c+\"_hour\"]  = df[c].dt.hour\n",
        "        df[c+\"_dow\"]   = df[c].dt.dayofweek\n",
        "        df.drop(columns=[c], inplace=True)\n",
        "    return df\n",
        "\n",
        "def auto_feature_crosses(Xdf, max_pairs=20):\n",
        "    nums = Xdf.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if len(nums) < 2:\n",
        "        return Xdf, []\n",
        "    vari = Xdf[nums].var().sort_values(ascending=False)\n",
        "    tops = vari.index[:max_pairs+2]\n",
        "    pairs = list(itertools.combinations(tops, 2))[:max_pairs]\n",
        "    for a, b in pairs:\n",
        "        Xdf[f\"{a}*{b}\"] = Xdf[a]*Xdf[b]\n",
        "    return Xdf, pairs\n",
        "\n",
        "def se_block(x, ratio=8, name=\"se\"):\n",
        "    channels = int(x.shape[-1])\n",
        "    s = layers.Reshape((1, channels), name=f\"{name}_reshape_in\")(x)\n",
        "    s = layers.GlobalAveragePooling1D(name=f\"{name}_gap\")(s)\n",
        "    s = layers.Dense(max(1, channels // ratio), activation=\"relu\", name=f\"{name}_fc1\")(s)\n",
        "    s = layers.Dense(channels, activation=\"sigmoid\", name=f\"{name}_fc2\")(s)\n",
        "    s = layers.Reshape((channels,), name=f\"{name}_reshape_out\")(s)\n",
        "    return layers.Multiply(name=f\"{name}_scale\")([x, s])\n",
        "\n",
        "def make_cosine_lr_fn(initial_lr, decay_epochs=40, alpha=0.0002):\n",
        "    def lr_fn(epoch):\n",
        "        t = min(epoch, decay_epochs)\n",
        "        cos_val = 0.5 * (1 + math.cos(math.pi * t / decay_epochs))\n",
        "        lr = initial_lr * (alpha + (1 - alpha) * cos_val)\n",
        "        return lr\n",
        "    return lr_fn\n",
        "\n",
        "print(\"Loading:\", CSV_PATH)\n",
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "print(\"Loaded shape:\", df.shape)\n",
        "\n",
        "df = df.drop(columns=[c for c in df.columns if is_id_like(c)], errors=\"ignore\")\n",
        "nunique = df.nunique(dropna=False)\n",
        "df = df.drop(columns=nunique[nunique <= 1].index.tolist())\n",
        "\n",
        "df = add_datetime_parts(df, TARGET)\n",
        "\n",
        "if TARGET not in df.columns:\n",
        "    raise ValueError(f\"Target column '{TARGET}' not found in dataset\")\n",
        "\n",
        "y_raw = df[TARGET].values\n",
        "classes = np.unique(y_raw)\n",
        "class_map = {str(c): i for i, c in enumerate(classes)}\n",
        "y = np.array([class_map[str(v)] for v in y_raw], dtype=int)\n",
        "\n",
        "X = df.drop(columns=[TARGET]).copy()\n",
        "\n",
        "for c in X.columns:\n",
        "    if X[c].dtype == object:\n",
        "        _, inv = np.unique(X[c].astype(str), return_inverse=True)\n",
        "        X[c] = inv.astype(np.float32)\n",
        "\n",
        "X, used_pairs = auto_feature_crosses(X, max_pairs=20)\n",
        "print(\"Added feature crosses:\", used_pairs)\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X.values, y, test_size=VAL_SIZE, random_state=SEED, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=VAL_SIZE, random_state=SEED, stratify=y_temp\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train.astype(np.float32))\n",
        "X_val   = scaler.transform(X_val.astype(np.float32))\n",
        "X_test  = scaler.transform(X_test.astype(np.float32))\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "num_classes = len(classes)\n",
        "print(\"Input dim:\", input_dim, \"Num classes:\", num_classes)\n",
        "print(\"Train/Val/Test shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
        "\n",
        "def build_widedeep_with_bn(input_dim, num_classes, hidden_sizes, dropout_rate, l2_reg):\n",
        "    inputs = keras.Input(shape=(input_dim,))\n",
        "    wide_logits = layers.Dense(num_classes, kernel_regularizer=regularizers.l2(l2_reg))(inputs)\n",
        "    x = inputs\n",
        "    for i, h in enumerate(hidden_sizes, 1):\n",
        "        x = layers.Dense(h, kernel_initializer=\"he_normal\",\n",
        "                         kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation(\"swish\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "        x = se_block(x, ratio=8, name=f\"se_{i}\")\n",
        "    deep_logits = layers.Dense(num_classes, kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    combined = layers.Add()([wide_logits, deep_logits])\n",
        "    out = layers.Activation(\"softmax\", dtype=\"float32\")(combined)\n",
        "    return keras.Model(inputs, out)\n",
        "\n",
        "def train_one_run(seed, epochs, run_name=\"run\"):\n",
        "    print(f\"\\n--- Training seed={seed} ({run_name}) ---\")\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    with strategy.scope():\n",
        "        model = build_widedeep_with_bn(\n",
        "            input_dim=input_dim,\n",
        "            num_classes=num_classes,\n",
        "            hidden_sizes=HIDDEN_SIZES,\n",
        "            dropout_rate=DROPOUT_RATE,\n",
        "            l2_reg=L2_REG\n",
        "        )\n",
        "        opt = keras.optimizers.Adam(learning_rate=INITIAL_LR)\n",
        "        model.compile(\n",
        "            optimizer=opt,\n",
        "            loss=keras.losses.CategoricalCrossentropy(label_smoothing=LABEL_SMOOTH),\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "    y_train_oh = keras.utils.to_categorical(y_train, num_classes)\n",
        "    y_val_oh   = keras.utils.to_categorical(y_val, num_classes)\n",
        "\n",
        "    lr_schedule = make_cosine_lr_fn(INITIAL_LR, decay_epochs=40)\n",
        "    ckpt_path = os.path.join(SAVE_DIR, f\"best_{run_name}_seed{seed}.keras\")\n",
        "    cb_list = [\n",
        "        callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=1),\n",
        "        callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True, verbose=1),\n",
        "        callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=6, verbose=1, min_lr=1e-6),\n",
        "        callbacks.LearningRateScheduler(lambda ep: lr_schedule(ep), verbose=0)\n",
        "    ]\n",
        "\n",
        "    hist = model.fit(\n",
        "        X_train, y_train_oh,\n",
        "        validation_data=(X_val, y_val_oh),\n",
        "        epochs=epochs,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=cb_list,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        model.load_weights(ckpt_path)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    preds_proba = model.predict(X_test, batch_size=1024)\n",
        "    preds = preds_proba.argmax(axis=1)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    print(f\"Seed {seed} test accuracy: {acc:.6f}\")\n",
        "    return preds_proba, acc, hist\n",
        "\n",
        "final_results = {}\n",
        "for epochs in EPOCH_BUDGETS:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"Running experiments for budget {epochs} epochs (early stopping may stop sooner)\")\n",
        "\n",
        "    per_run_preds = []\n",
        "    per_run_accs = []\n",
        "    per_run_hists = []\n",
        "\n",
        "    runs = ENSEMBLE_RUNS if ENSEMBLE_RUNS >= 1 else 1\n",
        "    for r in range(runs):\n",
        "        seed = SEED + r * 7\n",
        "        preds_proba, acc, hist = train_one_run(seed, epochs, run_name=f\"e{epochs}_r{r}\")\n",
        "        per_run_preds.append(preds_proba)\n",
        "        per_run_accs.append(acc)\n",
        "        per_run_hists.append(hist)\n",
        "\n",
        "    if runs > 1:\n",
        "        avg_preds = np.mean(np.stack(per_run_preds, axis=0), axis=0)\n",
        "        final_preds = avg_preds.argmax(axis=1)\n",
        "        ensemble_acc = accuracy_score(y_test, final_preds)\n",
        "        print(f\"Ensemble (n={runs}) test accuracy: {ensemble_acc:.6f}\")\n",
        "    else:\n",
        "        ensemble_acc = per_run_accs[0]\n",
        "        print(f\"Single-run test accuracy: {ensemble_acc:.6f}\")\n",
        "\n",
        "    final_results[epochs] = {\n",
        "        \"per_run_accs\": [float(a) for a in per_run_accs],\n",
        "        \"ensemble_acc\": float(ensemble_acc)\n",
        "    }\n",
        "\n",
        "with open(RESULTS_JSON, \"w\") as f:\n",
        "    json.dump(final_results, f, indent=2)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "x = sorted(final_results.keys())\n",
        "y = [final_results[k][\"ensemble_acc\"] for k in x]\n",
        "plt.plot(x, y, marker=\"o\")\n",
        "for a,b in zip(x,y):\n",
        "    plt.text(a, b, f\"{b:.4f}\", ha=\"center\", va=\"bottom\")\n",
        "plt.title(\"SE + WideDeep (improved) Accuracy vs Epoch Budgets\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Test Accuracy\")\n",
        "plt.grid(True)\n",
        "plt.savefig(ACCURACY_PNG, dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(\"Saved results JSON:\", RESULTS_JSON)\n",
        "print(\"Saved accuracy plot:\", ACCURACY_PNG)\n",
        "print(\"Finished. Results saved at:\", SAVE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nDvpqg-b1KBt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
